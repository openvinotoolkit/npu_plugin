//
// Copyright (C) 2023 Intel Corporation.
// SPDX-License-Identifier: Apache 2.0
//

#include "vpux/compiler/VPU37XX/dialect/VPU/IR/ops_interfaces.hpp"

#include "vpux/compiler/dialect/VPU/utils/layer_post_ops_utils.hpp"
#include "vpux/compiler/dialect/VPUIP/nce_invariant.hpp"

#include <llvm/ADT/TypeSwitch.h>

using namespace vpux;

namespace {

//
// LayerWithPostOpModel37XX
//

bool isSupportedHWPostOp(mlir::Operation* mainOp, mlir::Operation* postOp, const LogCb& logCb) {
    return llvm::TypeSwitch<mlir::Operation*, bool>(postOp)
            .Case<IE::ReLUOp>([](IE::ReLUOp) {
                return true;
            })
            // TODO: remove option after E#83187
            .Case<IE::ClampOp>([&](IE::ClampOp clampOp) {
                const auto isQuantized = vpux::VPU::checkForQuantization(mainOp, postOp);
                if (clampOp != nullptr) {
                    const auto minVal = clampOp.getMinAttr().getValueAsDouble();
                    if (!isDoubleEqual(minVal, 0.0) && !isQuantized) {
                        logCb(llvm::formatv("{0} is not quantized and does not have 0 as minVal at `{1}`",
                                            postOp->getName(), postOp->getLoc()));
                        return false;
                    }
                }
                return true;
            })
            .Case<IE::LeakyReluOp>([&](IE::LeakyReluOp) {
                if (mlir::isa<IE::MaxPoolOp>(mainOp)) {
                    logCb(llvm::formatv("{0} does not support fusing with {1} for this HW platform at `{2}`",
                                        mainOp->getName(), postOp->getName(), postOp->getLoc()));
                    return false;
                }
                return true;
            })
            .Default([&](mlir::Operation*) {
                logCb(llvm::formatv("{0} at `{1}` is not supported on this HW platform", postOp->getName(),
                                    postOp->getLoc()));
                return false;
            });
}

template <class MainOpType>
class LayerWithPostOpModel final :
        public IE::LayerWithPostOpInterface::ExternalModel<LayerWithPostOpModel<MainOpType>, MainOpType> {
public:
    bool isSupportedPostOp(mlir::Operation* mainOp, mlir::Operation* postOp, const LogCb& logCb) const {
        if (VPU::getCompilationMode(postOp) == VPU::CompilationMode::ReferenceSW) {
            return false;
        }

        if (!isSupportedHWPostOp(mainOp, postOp, logCb)) {
            return false;
        }

        return VPUIP::NCEInvariant::verifyKernel(mlir::cast<MainOpType>(mainOp)).succeeded();
    }

    bool isSupportedClampOp(mlir::Operation* mainOp, mlir::Operation* clampOp, const LogCb& logCb) const {
        if (VPU::getCompilationMode(clampOp) == VPU::CompilationMode::ReferenceSW) {
            return false;
        }

        if (!VPU::isSupportedHWClampOp(mainOp, clampOp, logCb)) {
            return false;
        }

        return VPUIP::NCEInvariant::verifyKernel(mlir::cast<MainOpType>(mainOp)).succeeded();
    }

    void setLayerClampOp(mlir::Operation* mainOp, mlir::Operation* activationOp) const {
        VPU::setHWClampOp(mainOp, activationOp);
    }
};

}  // namespace

//
// setupExtraInterfaces
//

void vpux::VPU::arch37xx::registerLayerWithPostOpModelInterface(mlir::DialectRegistry& registry) {
    registry.addExtension(+[](mlir::MLIRContext* ctx, IE::IEDialect*) {
        IE::ConvolutionOp::attachInterface<LayerWithPostOpModel<IE::ConvolutionOp>>(*ctx);
        IE::TransposedConvolutionOp::attachInterface<LayerWithPostOpModel<IE::TransposedConvolutionOp>>(*ctx);
        IE::GroupConvolutionOp::attachInterface<LayerWithPostOpModel<IE::GroupConvolutionOp>>(*ctx);
        IE::MaxPoolOp::attachInterface<LayerWithPostOpModel<IE::MaxPoolOp>>(*ctx);
        IE::AvgPoolOp::attachInterface<LayerWithPostOpModel<IE::AvgPoolOp>>(*ctx);
        IE::AddOp::attachInterface<LayerWithPostOpModel<IE::AddOp>>(*ctx);
        IE::SubtractOp::attachInterface<LayerWithPostOpModel<IE::SubtractOp>>(*ctx);
    });
}
