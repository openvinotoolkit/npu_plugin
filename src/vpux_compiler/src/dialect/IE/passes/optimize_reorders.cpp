//
// Copyright (C) 2022 Intel Corporation.
// SPDX-License-Identifier: Apache 2.0
//

#include "vpux/compiler/dialect/IE/passes.hpp"

#include "vpux/compiler/dialect/const/ops.hpp"
#include "vpux/compiler/utils/adjust_layout_utils.hpp"
#include "vpux/compiler/utils/error.hpp"
#include "vpux/compiler/utils/permute_utils.hpp"
#include "vpux/compiler/utils/rewriter.hpp"
#include "vpux/compiler/utils/types.hpp"
#include "vpux/utils/core/range.hpp"

#include <mlir/Transforms/GreedyPatternRewriteDriver.h>

using namespace vpux;

namespace {

// If there are nonTrivial Reorders before and after Tile, the two Reorders will be fused after switch Tile and Reorder.

bool isBeneficialReorderFuse(IE::TileOp tileOp) {
    auto inputReorderOp = tileOp.getInput().getDefiningOp<IE::ReorderOp>();

    if (!tileOp.getOutput().hasOneUse()) {
        return false;
    }

    bool isTrivial = inputReorderOp == nullptr ? true : isTrivialReorder(inputReorderOp);

    auto outputReorderOp = mlir::dyn_cast<IE::ReorderOp>(*(tileOp.getOutput().user_begin()));
    isTrivial = isTrivial || (outputReorderOp == nullptr ? true : isTrivialReorder(outputReorderOp));

    return inputReorderOp && outputReorderOp && !isTrivial;
}

// For tileOp tile data in high dim is more efficient than tile date in low dim.
// For example tileOp 1x16x1x1 -> 1x16x100x100 (repeatsValues = [1,1,100,100]), NHWC is more efficient than NCHW layout,
// because NHWC will tile data in the higher dime(H and W of NHWC), the tileOp will convert to no stride DMA. but for
// NCHW will tile data in the lower dim (H and W of NCHW), the tileOp will convert to stride DMA which is low efficient.

bool isBeneficialSwitch(IE::TileOp tileOp, vpux::DimsOrder origOrder, vpux::DimsOrder switchedOrder) {
    auto outputShape = getShape(tileOp.getOutput());

    if (std::all_of(outputShape.begin(), outputShape.end(), [](auto shape) {
            return shape == 1;
        })) {
        return false;
    }

    auto repeatsValues = parseIntArrayAttr<int64_t>(tileOp.getRepeatsValuesAttr());

    SmallVector<int32_t> repeatAxesIndexVal, notRepeatAndHasValueAxesIndexVal;

    // Find the tile dim axes and not tile and has value(size != 1) dim axes.
    // Eg in tileOp 1x16x1x1 -> 1x16x100x100, tile dim axes is [2, 3], not-tile-and-has-value dim axes is [1]. Dim 0
    // size is 1, this dim has no impact on the reorder optimization.
    for (size_t ind = 0; ind < repeatsValues.size(); ++ind) {
        if (repeatsValues[ind] == 1 && outputShape[Dim(ind)] != 1) {
            notRepeatAndHasValueAxesIndexVal.push_back(ind);
        } else if (repeatsValues[ind] > 1) {
            repeatAxesIndexVal.push_back(ind);
        }
    }

    if (notRepeatAndHasValueAxesIndexVal.empty()) {
        return false;
    }

    // Check if all NotRepeatAndHasValueAxes larger than RepeatAxes.
    // Eg in tileOp 1x16x1x1(NHWC) -> 1x16x100x100(NHWC), repeat dim axes is [2, 3], not-repeat-dim axes is [0, 1]. For
    // NHWC layout, the real repeat dim axes is [1, 2], real not-repeat dim axes is [0, 3], and real
    // not-repeat-and-has-value dim axes is [3]. So we need check all of the not-repeat-and-has-value dim axes be larger
    // than the repeat dim axes.
    auto isAllNotRepeatAndHasValueAxesLargerThanRepeatAxes = [&](const vpux::DimsOrder& order,
                                                                 ArrayRef<int32_t> repeatAxes,
                                                                 ArrayRef<int32_t> notRepeatAndHasValueAxes) {
        SmallVector<int32_t> realRepeatAxes, realNotRepeatAndHasValueAxes;
        for (auto notRepeatAndHasValueAxis : notRepeatAndHasValueAxes) {
            realNotRepeatAndHasValueAxes.push_back(order.dimPos(Dim(notRepeatAndHasValueAxis)));
        }
        for (auto repeatAxis : repeatAxes) {
            realRepeatAxes.push_back(order.dimPos(Dim(repeatAxis)));
        }

        std::sort(realNotRepeatAndHasValueAxes.begin(), realNotRepeatAndHasValueAxes.end());
        std::sort(realRepeatAxes.begin(), realRepeatAxes.end());

        return realNotRepeatAndHasValueAxes.front() > realRepeatAxes.back();
    };

    return !isAllNotRepeatAndHasValueAxesLargerThanRepeatAxes(origOrder, repeatAxesIndexVal,
                                                              notRepeatAndHasValueAxesIndexVal) &&
           isAllNotRepeatAndHasValueAxesLargerThanRepeatAxes(switchedOrder, repeatAxesIndexVal,
                                                             notRepeatAndHasValueAxesIndexVal);
}

//
// ReorderWithShapeChange
//
template <class ConcreteOp>
class ReorderWithShapeChange final : public mlir::OpRewritePattern<ConcreteOp> {
public:
    ReorderWithShapeChange(mlir::MLIRContext* ctx, Logger log): mlir::OpRewritePattern<ConcreteOp>(ctx), _log(log) {
        this->setDebugName("ReorderWithShapeChange");
    }

public:
    mlir::LogicalResult matchAndRewrite(ConcreteOp origReshapeOp, mlir::PatternRewriter& rewriter) const final;

private:
    Logger _log;
};

// This function is to find groups of axes that are reshaped
// For example, (3,16,8,2)#NCHW -> Reshape -> (1,48,4,4)#NCHW
// The result will be {{N, C}, {H, W}}
SmallVector<SmallVector<Dim>> getReshapedAxes(ShapeRef inShape, ShapeRef outShape, DimsOrder order) {
    SmallVector<SmallVector<Dim>> reshapedAxes;
    SmallVector<Dim> reshapedGroup;
    int64_t inProduct;
    int64_t outProduct;
    bool startMatch = false;
    for (const auto& dim : order.toPermutation()) {
        auto inDimSize = inShape[dim];
        auto outDimSize = outShape[dim];
        if (startMatch) {
            // Keep iterating dims until the total element sizes are the same, and those dims form a group
            reshapedGroup.push_back(dim);
            inProduct *= inDimSize;
            outProduct *= outDimSize;
            if (inProduct == outProduct) {
                reshapedAxes.push_back(reshapedGroup);
                startMatch = false;
            }
        } else {
            // Start matching if dim sizes are different
            if (inDimSize != outDimSize) {
                reshapedGroup.assign({dim});
                inProduct = inDimSize;
                outProduct = outDimSize;
                startMatch = true;
            }
        }
    }
    VPUX_THROW_UNLESS(startMatch == false, "Reshape's input {0} and output {1} are not matched", inShape, outShape);

    return reshapedAxes;
}

// Reorder can only propagate if the order of Reshape's reshaped axes are kept the same
// For exmaple, (1,16,8,2)#NHWC -> Reorder -> (1,16,8,2)#NCHW -> Reshape -> (1,16,4,4)#NCHW
// Only H & W are reshaped and their relative order stays the same
// Thus, the Reorder can be propagated through the Reshape like below:
// (1,16,8,2)#NHWC -> Reshape -> (1,16,4,4)#NHWC -> Reorder -> (1,16,4,4)#NCHW
bool isReshapeInImmutableGroup(const SmallVector<SmallVector<Dim>>& reshapedAxes, const DimsOrder& order) {
    for (const auto& group : reshapedAxes) {
        auto dimIter = group.begin();
        auto prevPos = order.dimPos(*dimIter);
        while (++dimIter != group.end()) {
            auto curPos = order.dimPos(*dimIter);
            if (curPos - prevPos != 1) {
                return false;
            }
            prevPos = curPos;
        }
    }

    return true;
}

// Reorder could be propagated when irrelevant shapes are removed (shape=1) and
// the memory permutation of the reshaped tensor remains the same as before the Reorder
// We check two conditions:
// 1. If propagated new Reorder's MemShape is identical with original shapeChangeOp's output MemShape.
// 2. If propagated new Reorder's permutation is identical with original shapeChangeOp's output permutation.
//
// Eg1. (1,1,64,64)#NWHC ->Reorder-> (1,1,64,64)#NCHW ->ShapeChangeOp-> (1,64,64,1)#NCHW
//   MemShape: (1,64,64,1) ->Reorder-> (1,1,64,64) ->ShapeChangeOp-> (1,64,64,1)
//   NormMemShape: (0,1,2,0) ->Reorder-> (0,0,2,1) ->ShapeChangeOp-> (0,2,1,0)
//   MemShape if propagateReorder: (1,64,64,1) ->ShapeCast-> (1,1,64,64) ->Reorder-> (1,64,64,1)
//   NormMemShape if propagateReorder: (0,1,2,0) ->ShapeCast-> (0,0,1,2) ->Reorder-> (0,2,1,0)
//   return ture as (64,64) == (64,64) && (2,1) == (2,1)
//
// Eg2. (1,1,64,64)#NCWH ->Reorder-> (1,1,64,64)#NCHW ->ShapeChangeOp-> (64,64,1,1)#NCHW
//   MemShape: (1,1,64,64) ->Reorder-> (1,1,64,64) ->ShapeChangeOp-> (64,64,1,1)
//   NormMemShape: (0,0,1,2) ->Reorder-> (0,0,2,1) ->ShapeChangeOp-> (2,1,0,0)
//   MemShape if propagateReorder:  (1,1,64,64) ->ShapeCast-> (64,64,1,1) ->Reorder-> (64,64,1,1)
//   NormMemShape if propagateReorder: (0,0,1,2) ->ShapeCast-> (1,2,0,0) ->ReorderOp-> (1,2,0,0)
//   return false as (64,64) == (64,64) && (2,1) != (1,2)
bool isCompatibleMemReshape(vpux::NDTypeInterface inType, vpux::NDTypeInterface outType) {
    auto inMemShape = inType.getMemShape();
    const auto inOrder = inType.getDimsOrder();
    const auto newOutType = outType.changeDimsOrder(inOrder);
    auto newOutMemShape = newOutType.getMemShape();

    // return normalized memShape
    // eg1: (1,1,64,64)#NHWC -> (0,1,2,0)
    // eg2: (1,1,64,64)#NCHW -> (0,0,1,2)
    auto getNormalizedMemShape = [](MemShapeRef memShape) -> MemShape {
        SmallVector<int64_t> normalizedVec;
        int64_t nonTrivailNum = 1;
        for (auto& shape : memShape) {
            if (shape == 1) {
                normalizedVec.push_back(0);
            } else {
                normalizedVec.push_back(nonTrivailNum++);
            }
        }
        return MemShape(normalizedVec);
    };

    // cal original normalized mem shape
    auto inNormMemShape = getNormalizedMemShape(inMemShape);
    auto originalReorderPermutation = getPermutationFromOrders(inOrder, outType.getDimsOrder(), inType.getContext());
    auto origReorderNormMemShape = applyPerm(inNormMemShape, originalReorderPermutation);

    // get new reshape's normalized mem permutation
    auto newReshapeNormMemShape = getNormalizedMemShape(newOutMemShape);
    auto newOutNormMemShape = applyPerm(newReshapeNormMemShape, originalReorderPermutation);

    // ignore trivial dims
    origReorderNormMemShape.erase(std::remove(origReorderNormMemShape.begin(), origReorderNormMemShape.end(), 0),
                                  origReorderNormMemShape.end());
    newOutNormMemShape.erase(std::remove(newOutNormMemShape.begin(), newOutNormMemShape.end(), 0),
                             newOutNormMemShape.end());

    // ignore shape is one
    inMemShape.erase(std::remove(inMemShape.begin(), inMemShape.end(), 1), inMemShape.end());
    newOutMemShape.erase(std::remove(newOutMemShape.begin(), newOutMemShape.end(), 1), newOutMemShape.end());

    return inMemShape == newOutMemShape && origReorderNormMemShape == newOutNormMemShape;
}

// Maintain the Reorder -> PermuteCast -> Reorder chain as it can later be reduced to a single operation
bool isMaintainPattern(mlir::Operation* op) {
    if (auto prevPermuteCastOp = op->getOperand(0).getDefiningOp<IE::PermuteCastOp>()) {
        if (auto prevReorderOp = prevPermuteCastOp.getOperand().getDefiningOp<IE::ReorderOp>()) {
            return true;
        }
    }

    return false;
}

template <class ConcreteOp>
mlir::LogicalResult ReorderWithShapeChange<ConcreteOp>::matchAndRewrite(ConcreteOp origReshapeOp,
                                                                        mlir::PatternRewriter& rewriter) const {
    const auto origReshapeInput = origReshapeOp->getOperand(0);

    // Propagate Reorder through Reshape only with pattern: Reorder -> Reshape -> Reorder
    // two Reorders could fuse together
    auto origReorderOp = origReshapeInput.template getDefiningOp<IE::ReorderOp>();
    if (origReorderOp == nullptr) {
        return mlir::failure();
    }
    auto outputReorderOp = mlir::dyn_cast<IE::ReorderOp>(*(origReshapeOp->getResult(0).user_begin()));
    if (outputReorderOp == nullptr) {
        return mlir::failure();
    }

    _log.trace("Got Reorder at '{0}' -> {1} at '{2}' pair", origReorderOp->getLoc(), origReshapeOp->getName(),
               origReshapeOp->getLoc());

    const auto origReshapeOutput = origReshapeOp->getResult(0);
    const auto inOrder = DimsOrder::fromValue(origReorderOp.getInput());
    const auto outOrder = DimsOrder::fromAffineMap(origReorderOp.getDstOrder());
    const auto reshapeOutOrder = origReshapeOutput.getType().template dyn_cast<vpux::NDTypeInterface>().getDimsOrder();
    if (outOrder != reshapeOutOrder) {
        return matchFailed(_log.nest(), rewriter, origReshapeOp,
                           "Reshape's input order {0} and output order {1} are not the same", outOrder,
                           reshapeOutOrder);
    }

    const auto reshapeInShape = getShape(origReshapeInput);
    const auto reshapeOutShape = getShape(origReshapeOutput);
    const auto reshapedAxes = getReshapedAxes(reshapeInShape, reshapeOutShape, outOrder);

    if (!isReshapeInImmutableGroup(reshapedAxes, inOrder) &&
        !isCompatibleMemReshape(origReorderOp.getInput().getType(), origReshapeOutput.getType())) {
        return matchFailed(_log.nest(), rewriter, origReshapeOp,
                           "The orders of reshaped axes {0} are different in input order {2} and output order {3}, ",
                           "and the shape change op is not a trivial mem reshape ", reshapedAxes, inOrder, outOrder);
    }

    auto shapeAttr = getIntArrayAttr(origReshapeOp.getContext(), reshapeOutShape);
    auto shapeCastOp = rewriter.create<IE::ShapeCastOp>(origReshapeOp->getLoc(), origReorderOp.getInput(), shapeAttr);
    rewriter.replaceOpWithNewOp<IE::ReorderOp>(origReshapeOp, shapeCastOp.getResult(), origReorderOp.getDstOrderAttr());

    return mlir::success();
}

//
// ReorderWithSubView
//

class ReorderWithSubView final : public mlir::OpRewritePattern<IE::SliceOp> {
public:
    ReorderWithSubView(mlir::MLIRContext* ctx, Logger log): mlir::OpRewritePattern<IE::SliceOp>(ctx), _log(log) {
        setDebugName("ReorderWithSubView");
    }

public:
    mlir::LogicalResult matchAndRewrite(IE::SliceOp origSubViewOp, mlir::PatternRewriter& rewriter) const final;

private:
    Logger _log;
};

mlir::LogicalResult ReorderWithSubView::matchAndRewrite(IE::SliceOp origSubViewOp,
                                                        mlir::PatternRewriter& rewriter) const {
    auto origReorderOp = origSubViewOp.getSource().getDefiningOp<IE::ReorderOp>();
    if (origReorderOp == nullptr) {
        return mlir::failure();
    }

    if (isMaintainPattern(origReorderOp.getOperation())) {
        return mlir::failure();
    }

    _log.trace("Got reorder at '{0}' -> subview at '{1}' pair", origReorderOp->getLoc(), origSubViewOp->getLoc());

    auto getUserOp = [](mlir::Operation* op) -> mlir::Operation* {
        mlir::Operation* user = op;
        while (mlir::isa<IE::PermuteCastOp, IE::AffineReshapeOp>(user) && user->hasOneUse()) {
            user = *user->getUsers().begin();
        }

        return user;
    };

    // In case "ReorderOp + SliceOp", if ReorderOp has no permutation for last dim (For example
    // affine_map<(d0, d2, d3, d1, d4) -> (d0, d1, d2, d3, d4)>), and the SliceOp output shape size for last dim
    // is 1 (For example, d0xd1xd2xd3x1), then the new Reorder <(d0, d2, d3, d1, 1) -> (d0, d1, d2, d3, 1)>
    // after swap will make it worse from performance perspective as inefficient DMA
    if (!origReorderOp.getResult().hasOneUse()) {
        bool allSlicesUsers = true;
        bool benefitToSwap = true;
        bool hasReorderUser = false;
        for (auto* reorderUser : llvm::make_early_inc_range(origReorderOp->getUsers())) {
            auto reorderUserSliceOp = mlir::dyn_cast<IE::SliceOp>(reorderUser);
            if (reorderUserSliceOp == nullptr) {
                allSlicesUsers = false;
                break;
            }

            auto reorderInputDimsOrder = DimsOrder::fromValue(origReorderOp.getInput());
            auto reorderOutputDimsOrder = DimsOrder::fromValue(origReorderOp.getOutput());
            auto reorderInputPerm = reorderInputDimsOrder.toPermutation();
            auto reorderOutputPerm = reorderOutputDimsOrder.toPermutation();
            auto inputPermEnd = (reorderInputPerm.end() - 1)->ind();
            auto outputPermEnd = (reorderOutputPerm.end() - 1)->ind();
            const auto sliceShape = parseIntArrayAttr<int64_t>(reorderUserSliceOp.getStaticSizes());

            if (inputPermEnd == outputPermEnd && sliceShape[outputPermEnd] == 1) {
                benefitToSwap = false;
            }

            auto sliceUser = *reorderUser->getUsers().begin();
            if (reorderUser->hasOneUse() && sliceUser != nullptr && mlir::isa<IE::ReorderOp>(getUserOp(sliceUser))) {
                // Swap if reorder can be fused with reorder post slice operation
                hasReorderUser = true;
            }
        }

        if (allSlicesUsers && !benefitToSwap && !hasReorderUser) {
            return mlir::failure();
        }
    }

    auto newSubViewOp =
            rewriter.create<IE::SliceOp>(origSubViewOp->getLoc(), origReorderOp.getInput(),
                                         origSubViewOp.getStaticOffsetsAttr(), origSubViewOp.getStaticSizesAttr());

    rewriter.replaceOpWithNewOp<IE::ReorderOp>(origSubViewOp, newSubViewOp.getResult(),
                                               origReorderOp.getDstOrderAttr());
    return mlir::success();
}

//
// ReorderWithTile
//

class ReorderWithTile final : public mlir::OpRewritePattern<IE::TileOp> {
public:
    ReorderWithTile(mlir::MLIRContext* ctx, Logger log): mlir::OpRewritePattern<IE::TileOp>(ctx), _log(log) {
        setDebugName("ReorderWithTile");
    }

public:
    mlir::LogicalResult matchAndRewrite(IE::TileOp origTileOp, mlir::PatternRewriter& rewriter) const final;

private:
    Logger _log;
};

mlir::LogicalResult ReorderWithTile::matchAndRewrite(IE::TileOp origTileOp, mlir::PatternRewriter& rewriter) const {
    if (isBeneficialReorderFuse(origTileOp)) {
        return mlir::failure();
    }

    auto origReorderOp = mlir::dyn_cast<IE::ReorderOp>(*(origTileOp.getOutput().user_begin()));
    if (origReorderOp == nullptr) {
        return mlir::failure();
    }
    // Avoid loop rewriting with ReorderWithLayer
    if (mlir::isa<IE::ReorderOp>(*(origReorderOp.getOutput().user_begin()))) {
        return mlir::failure();
    }

    if (isMaintainPattern(origReorderOp.getOperation())) {
        return mlir::failure();
    }

    _log.trace("Got tile at '{0}' -> reorder at '{1}' pair", origTileOp->getLoc(), origReorderOp->getLoc());

    if (!isBeneficialSwitch(origTileOp, DimsOrder::fromValue(origReorderOp.getInput()),
                            DimsOrder::fromValue(origReorderOp.getOutput()))) {
        return mlir::failure();
    }

    auto newReorderOp = rewriter.create<IE::ReorderOp>(origReorderOp->getLoc(), origTileOp.getInput(),
                                                       origReorderOp.getDstOrderAttr());

    auto outputType = origTileOp.getOutput().getType().cast<vpux::NDTypeInterface>();
    auto newOutputType = outputType.changeDimsOrder(DimsOrder::fromAffineMap(newReorderOp.getDstOrder()));

    rewriter.replaceOpWithNewOp<IE::TileOp>(origReorderOp, newOutputType, newReorderOp.getOutput(),
                                            origTileOp.getRepeats(), origTileOp.getRepeatsValuesAttr());

    return mlir::success();
}

//
// ReorderWithExpand
//

class ReorderWithExpand final : public mlir::OpRewritePattern<IE::ExpandOp> {
public:
    ReorderWithExpand(mlir::MLIRContext* ctx, Logger log): mlir::OpRewritePattern<IE::ExpandOp>(ctx), _log(log) {
        setDebugName("ReorderWithExpand");
    }

public:
    mlir::LogicalResult matchAndRewrite(IE::ExpandOp origExpandOp, mlir::PatternRewriter& rewriter) const final;

private:
    Logger _log;
};

//
//  The beneficial pattern:
//
//     input               input
//       |                   |
//     Reorder             Expand
//       |                   |
//     Expand   ==>        Reorder
//       |                   |
//     Slice(s)            Slice(s)
//       |                   |
//     Reorder(s)          Reorder(s)
//       |                   |
//     output              outPut
//
//  It's worth to swap parent Reorder and Expand,  the swaped Reorder will be handled by followup optimizations.
//

bool isBeneficialToSwapExpandReorders(IE::ExpandOp origExpandOp, IE::ReorderOp origReorderOp) {
    // If Reorder is not Trivial Permute, will swap
    if (!isTrivialReorder(origReorderOp)) {
        return true;
    }

    if (origExpandOp.getInput().isa<mlir::BlockArgument>()) {
        return false;
    }

    const auto expandOutput = origExpandOp.getOutput();

    SmallVector<IE::SliceOp> slices;

    for (auto userOp : expandOutput.getUsers()) {
        auto maybeSlice = mlir::dyn_cast_or_null<IE::SliceOp>(*userOp);
        if (maybeSlice == nullptr) {
            return false;
        }
        slices.push_back(maybeSlice);
    }

    if (slices.empty()) {
        return false;
    }

    SmallVector<mlir::Value> reorders;
    for (auto& userOp : slices) {
        auto sliceOutput = userOp.getResult();
        if (!sliceOutput.hasOneUse()) {
            return false;
        }
        auto maybeReorderOp = mlir::dyn_cast_or_null<IE::ReorderOp>(*sliceOutput.getUsers().begin());
        if (maybeReorderOp == nullptr) {
            return false;
        }
        reorders.push_back(maybeReorderOp);
    }

    return !reorders.empty();
}

void swapExpandWithReorder(mlir::PatternRewriter& rewriter, IE::ExpandOp expandOp, IE::ReorderOp origReorderOp) {
    mlir::OpBuilder::InsertionGuard guard(rewriter);
    rewriter.setInsertionPoint(expandOp);

    auto newExpandOp = rewriter.create<IE::ExpandOp>(expandOp->getLoc(), origReorderOp.getInput(),
                                                     expandOp.getPadsBeginAttr(), expandOp.getPadsEndAttr());

    rewriter.replaceOpWithNewOp<IE::ReorderOp>(expandOp, newExpandOp.getOutput(), origReorderOp.getDstOrderAttr());
}

mlir::LogicalResult ReorderWithExpand::matchAndRewrite(IE::ExpandOp origExpandOp,
                                                       mlir::PatternRewriter& rewriter) const {
    auto* ctx = origExpandOp->getContext();
    auto origReorderOp = origExpandOp.getInput().getDefiningOp<IE::ReorderOp>();
    if (origReorderOp == nullptr) {
        return mlir::failure();
    }

    _log.trace("Got reorder at '{0}' -> Expand at '{1}' pair", origReorderOp->getLoc(), origExpandOp->getLoc());

    const auto isExpand = [](mlir::Operation* reorderUser) -> bool {
        return mlir::isa<IE::ExpandOp>(reorderUser);
    };

    if (!llvm::all_of(origReorderOp->getUsers(), isExpand)) {
        return matchFailed(_log.nest(), rewriter, origExpandOp,
                           "Reorder has more than one user and they are heterogeneous");
    }

    if (!isBeneficialToSwapExpandReorders(origExpandOp, origReorderOp)) {
        return mlir::failure();
    }

    // If after swap Reorder cannot support by PermuteDMA, will not swap
    // Input (1x1x512x512, NCWH) -> Reorder (1x1x512x512, NHWC) -> Expand (1x16x512x512, NHWC)
    // After Swap the Reorder cannot convert to PermuteDMA
    // Input (1x1x512x512, NCWH) -> Expand (1x16x512x512, NCWH) -> Reorder (1x16x512x512, NHWC)
    auto expandOutType = origExpandOp.getOutput().getType().cast<vpux::NDTypeInterface>();
    auto newOrderInType = expandOutType.changeDimsOrder(DimsOrder::fromValue(origReorderOp.getInput()));
    auto newOrderOutType = expandOutType.changeDimsOrder(DimsOrder::fromValue(origReorderOp.getOutput()));
    auto memPerm = getPermutationFromOrders(newOrderInType.getDimsOrder(), newOrderOutType.getDimsOrder(), ctx);
    auto unsupportPermuteDMA = [&]() -> bool {
        const auto inShape = newOrderInType.getShape();
        return newOrderInType.getRank() == 4 && memPerm == mlir::AffineMap::getPermutationMap({0, 3, 2, 1}, ctx) &&
               inShape[Dims4D::Act::C] > 1 && inShape[Dims4D::Act::H] > 1 && inShape[Dims4D::Act::W] > 1;
    };

    if (unsupportPermuteDMA()) {
        return mlir::failure();
    }

    for (auto* reorderUser : llvm::make_early_inc_range(origReorderOp->getUsers())) {
        auto expandOp = mlir::cast<IE::ExpandOp>(reorderUser);
        swapExpandWithReorder(rewriter, expandOp, origReorderOp);
    }

    return mlir::success();
}

//
// ReorderWithExpandSlice
//

//  The beneficial pattern:
//
//       input(Not Reorder)   input
//          |                   |
//        Expand              Reorder
//          |                   |
//        Slice(s)   ==>      Expand
//          |                   |
//       Reorder(s)           Slice(s)
//          |                   |
//        output              Output
//  This is a cleanup pattern.
//  Move Reorder before Expand, it is beneficial if size of original Reorder(s) total size is larger than
//  new inserted Reorder.
//  Example:
//  (1,1,1,32032) -> Expand -> (1,16,1,32032) -> Slice -> (1,16,1,31995) -> Reorder
//                                            -> Slice -> (1,16,1,31995) -> Reorder
//  After this pass, the pattern:
//  (1,1,1,32032) -> Reorder -> Expand -> Slice
//                                     -> Slice
//  The size of the Reorders reduce from 16x31995x2 to 32032.

class ReorderWithExpandSlice final : public mlir::OpRewritePattern<IE::ExpandOp> {
public:
    ReorderWithExpandSlice(mlir::MLIRContext* ctx, Logger log): mlir::OpRewritePattern<IE::ExpandOp>(ctx), _log(log) {
        setDebugName("ReorderWithExpandSlice");
    }

public:
    mlir::LogicalResult matchAndRewrite(IE::ExpandOp origExpandOp, mlir::PatternRewriter& rewriter) const final;

private:
    Logger _log;
};

mlir::LogicalResult ReorderWithExpandSlice::matchAndRewrite(IE::ExpandOp origExpandOp,
                                                            mlir::PatternRewriter& rewriter) const {
    _log.trace("Got Expand at '{0}' ", origExpandOp->getLoc());
    if (mlir::isa_and_nonnull<IE::ReorderOp>(origExpandOp.getInput().getDefiningOp())) {
        return mlir::failure();
    }

    const auto expandOutput = origExpandOp.getOutput();
    SmallVector<IE::SliceOp> slices;

    for (auto userOp : expandOutput.getUsers()) {
        auto maybeSlice = mlir::dyn_cast_or_null<IE::SliceOp>(*userOp);
        if (maybeSlice == nullptr) {
            return mlir::failure();
        }
        slices.push_back(maybeSlice);
    }

    if (slices.empty()) {
        return mlir::failure();
    }

    SmallVector<IE::ReorderOp> reorders;
    for (auto& userOp : slices) {
        auto sliceOutput = userOp.getResult();
        if (!sliceOutput.hasOneUse()) {
            return mlir::failure();
        }
        auto maybeReorderOp = mlir::dyn_cast_or_null<IE::ReorderOp>(*sliceOutput.getUsers().begin());
        if (maybeReorderOp == nullptr) {
            return mlir::failure();
        }
        reorders.push_back(maybeReorderOp);
    }

    if (reorders.empty() || slices.size() != reorders.size()) {
        return mlir::failure();
    }

    int64_t subReordersTotalSize = 0;
    // check all the reorder op have the same input and output DimsOrder
    auto reorderOutputDimsOrder = DimsOrder::fromValue(reorders[0].getOutput());
    for (auto& reorderOp : reorders) {
        auto reorderOutputDimsOrderLocal = DimsOrder::fromValue(reorderOp.getOutput());
        if (reorderOutputDimsOrderLocal != reorderOutputDimsOrder) {
            return mlir::failure();
        }
        auto reorderOpOutputType = reorderOp.getOutput().getType().cast<vpux::NDTypeInterface>();
        subReordersTotalSize += reorderOpOutputType.getTotalAllocSize().count();
    }

    // Only benefit the first inserted Reorder size smaller than subslice total size.
    auto origExpandInputType = origExpandOp.getInput().getType().cast<vpux::NDTypeInterface>();
    auto origExpandInputSize = origExpandInputType.getTotalAllocSize().count();
    if (subReordersTotalSize <= origExpandInputSize) {
        _log.trace("Expand input Size: '{0}' larger than total size of Reorder(s): '{1}'. ", origExpandInputSize,
                   subReordersTotalSize);
        return mlir::failure();
    }

    auto newReorderOp = rewriter.create<IE::ReorderOp>(origExpandOp->getLoc(), origExpandOp.getInput(),
                                                       reorders[0].getDstOrderAttr());
    auto newExpandOp = rewriter.create<IE::ExpandOp>(origExpandOp->getLoc(), newReorderOp.getOutput(),
                                                     origExpandOp.getPadsBeginAttr(), origExpandOp.getPadsEndAttr());

    for (size_t index = 0; index < slices.size(); index++) {
        auto subSlice = slices[index];
        auto subReorder = reorders[index];
        auto newSliceOp = rewriter.create<IE::SliceOp>(subSlice->getLoc(), subReorder.getOutput().getType(),
                                                       newExpandOp.getOutput(), subSlice.getStaticOffsetsAttr(),
                                                       subSlice.getStaticSizesAttr());
        rewriter.replaceOp(subSlice, newSliceOp.getOutputs());
        subReorder.replaceAllUsesWith(subReorder.getInput());
        rewriter.eraseOp(subReorder);
    }
    return mlir::success();
}

//
// ReorderWithSplit
//

class ReorderWithSplit final : public mlir::OpRewritePattern<IE::SplitOp> {
public:
    ReorderWithSplit(mlir::MLIRContext* ctx, Logger log): mlir::OpRewritePattern<IE::SplitOp>(ctx), _log(log) {
        setDebugName("ReorderWithSplit");
    }

public:
    mlir::LogicalResult matchAndRewrite(IE::SplitOp origSplitOp, mlir::PatternRewriter& rewriter) const final;

private:
    Logger _log;
};

mlir::LogicalResult ReorderWithSplit::matchAndRewrite(IE::SplitOp origSplitOp, mlir::PatternRewriter& rewriter) const {
    if (origSplitOp.getAxis() != nullptr) {
        return mlir::failure();
    }

    auto origReorderOp = origSplitOp.getInput().getDefiningOp<IE::ReorderOp>();
    if (origReorderOp == nullptr) {
        return mlir::failure();
    }

    _log.trace("Got reorder at '{0}' -> Split at '{1}' pair", origReorderOp->getLoc(), origSplitOp->getLoc());

    const auto inOrder = DimsOrder::fromValue(origReorderOp.getInput());
    const auto outOrder = DimsOrder::fromValue(origReorderOp.getOutput());
    const auto dstOrderAttr = origReorderOp.getDstOrderAttr();
    auto newSplit = rewriter.create<IE::SplitOp>(origSplitOp->getLoc(), origReorderOp.getInput(), origSplitOp.getAxis(),
                                                 origSplitOp.getNumSplitsAttr(), origSplitOp.getAxisValueAttr());

    SmallVector<mlir::Value> newOutputs;
    newOutputs.reserve(origSplitOp.getOutputs().size());

    for (auto res : origSplitOp.getOutputs()) {
        if (res.getUses().empty()) {
            newOutputs.push_back(newSplit.getResult(res.getResultNumber()));
            continue;
        }

        _log.trace("Insert reorder '{0}' -> '{1}' for Split output at idx='{2}'.", inOrder, outOrder,
                   res.getResultNumber());
        auto reorder = rewriter.create<IE::ReorderOp>(origSplitOp->getLoc(), newSplit.getResult(res.getResultNumber()),
                                                      dstOrderAttr);
        newOutputs.push_back(reorder);
    }

    _log.trace("Replace Split with new output values.");
    rewriter.replaceOp(origSplitOp, newOutputs);

    return mlir::success();
}

//
// ReorderWithConcat
//

void replaceChildReorderWithNewConcat(IE::ConcatOp& origConcatOp, IE::ConcatOp& newConcatOp,
                                      mlir::PatternRewriter& rewriter, Logger log) {
    auto outputConcat = origConcatOp.getOutput();
    auto childReorderOp = mlir::dyn_cast_or_null<IE::ReorderOp>(*outputConcat.getUsers().begin());

    auto newOutputConcat = newConcatOp.getOutput();
    vpux::changeDimsOrder(newOutputConcat, DimsOrder::fromValue(childReorderOp.getOutput()), log);
    childReorderOp.getOutput().replaceAllUsesExcept(newOutputConcat,
                                                    llvm::SmallPtrSet<mlir::Operation*, 1>{newConcatOp});

    rewriter.eraseOp(childReorderOp);
    rewriter.eraseOp(origConcatOp);
}

//
//  The beneficial pattern:
//
//    input1    input2 ...                                           input3
//       |         |                                                    |
//    Reorder  Reorder ...input3                   input1  input2 ...Reorder
//           \     |     /                            \     |     /
//               Concat                 ==>               Concat
//                 |                                        |
//               Reorder                                  output
//                 |
//               output
//
//  It's worth to swap parent Reorder and Concat if the child Reorder can be eliminated.
//

bool isBeneficialToSwapConcatReorders(IE::ConcatOp& origConcatOp) {
    const auto outputConcat = origConcatOp.getOutput();
    if (!outputConcat.hasOneUse()) {
        return false;
    }

    auto maybeReorder = mlir::dyn_cast_or_null<IE::ReorderOp>(*outputConcat.getUsers().begin());
    if (maybeReorder == nullptr) {
        return false;
    }

    size_t nonReorderInput = 0;
    size_t reorderInput = 0;

    for (const auto& arg : origConcatOp.getInputs()) {
        if (auto argReorderOp = arg.getDefiningOp<IE::ReorderOp>()) {
            auto op = argReorderOp.getInput().getDefiningOp();
            if (mlir::isa_and_nonnull<Const::DeclareOp, IE::ReadValueOp>(op) || op == nullptr) {
                return false;
            }

            if (DimsOrder::fromValue(argReorderOp.getInput()) != DimsOrder::fromValue(maybeReorder.getOutput())) {
                return false;
            }

            reorderInput++;
        } else {
            nonReorderInput++;
        }
    }

    return nonReorderInput <= reorderInput;
}

class ReorderWithConcat final : public mlir::OpRewritePattern<IE::ConcatOp> {
public:
    ReorderWithConcat(mlir::MLIRContext* ctx, Logger log): mlir::OpRewritePattern<IE::ConcatOp>(ctx), _log(log) {
        setDebugName("ReorderWithConcat");
    }

public:
    mlir::LogicalResult matchAndRewrite(IE::ConcatOp origConcatOp, mlir::PatternRewriter& rewriter) const final;

private:
    Logger _log;
};

mlir::LogicalResult ReorderWithConcat::matchAndRewrite(IE::ConcatOp origConcatOp,
                                                       mlir::PatternRewriter& rewriter) const {
    SmallVector<mlir::Value> initialInputs;
    initialInputs.reserve(origConcatOp.getInputs().size());
    SmallVector<size_t> indexNonReorder;

    std::optional<DimsOrder> initialOrder;
    const bool isBeneficial = isBeneficialToSwapConcatReorders(origConcatOp);

    auto constNum = 0;
    mlir::Operation* origReorderOp = nullptr;

    for (const auto& it : origConcatOp.getInputs() | indexed) {
        auto arg = it.value();
        auto argReorderOp = arg.getDefiningOp<IE::ReorderOp>();
        if (argReorderOp == nullptr) {
            indexNonReorder.push_back(it.index());
            if (auto constOp = arg.getDefiningOp<Const::DeclareOp>()) {
                initialInputs.push_back(constOp.getOutput());
                constNum++;
                continue;
            }

            if (auto readValueOp = arg.getDefiningOp<IE::ReadValueOp>()) {
                initialInputs.push_back(readValueOp.getOutput());
                continue;
            }

            if (isBeneficial) {
                _log.trace("Got beneficial Concat: {0}", origConcatOp.getLoc());
                initialInputs.push_back(arg);
                continue;
            }

            return mlir::failure();
        }

        origReorderOp = argReorderOp.getOperation();
        const auto argOrder = DimsOrder::fromValue(argReorderOp.getInput());
        if (!initialOrder.has_value()) {
            initialOrder = argOrder;
        } else if (argOrder != initialOrder.value()) {
            return mlir::failure();
        }

        initialInputs.push_back(argReorderOp.getInput());
    }

    // To avoid affecting multiple branches optimization with reOrders before concat
    // Just skip only one non-const reorder input cases with the reorder-permutecast-reorder pattern
    if ((origConcatOp.getNumOperands() - constNum == 1) && origReorderOp) {
        if (isMaintainPattern(origReorderOp)) {
            return mlir::failure();
        }
    }

    if (!initialOrder.has_value()) {
        return mlir::failure();
    }

    const auto newConcatOrder = initialOrder.value();
    const auto originalConcatOrder = DimsOrder::fromValue(origConcatOp.getOutput());

    // Insert reorders for ConstOps and ReadValueOps */
    for (size_t ind = 0; ind < indexNonReorder.size(); ++ind) {
        const auto index = indexNonReorder[ind];
        mlir::OpBuilder::InsertionGuard guard(rewriter);
        rewriter.setInsertionPointAfterValue(initialInputs[index]);
        auto reorderOp = rewriter.create<IE::ReorderOp>(origConcatOp->getLoc(), initialInputs[index],
                                                        newConcatOrder.toAffineMap(rewriter.getContext()));
        initialInputs[index] = reorderOp.getOutput();
    }

    auto newConcat = rewriter.create<IE::ConcatOp>(origConcatOp->getLoc(), initialInputs, origConcatOp.getPerAxisAttr(),
                                                   origConcatOp.getStaticOffsetsAttr());

    if (isBeneficial) {
        replaceChildReorderWithNewConcat(origConcatOp, newConcat, rewriter, _log);
    } else {
        rewriter.replaceOpWithNewOp<IE::ReorderOp>(origConcatOp, origConcatOp.getType(), newConcat.getOutput(),
                                                   originalConcatOrder.toAffineMap(origConcatOp.getContext()));
    }

    return mlir::success();
}

//
// ReorderWithQuantCast
//

class ReorderWithQuantCast final : public mlir::OpRewritePattern<IE::QuantizeCastOp> {
public:
    ReorderWithQuantCast(mlir::MLIRContext* ctx, Logger log)
            : mlir::OpRewritePattern<IE::QuantizeCastOp>(ctx), _log(log) {
        setDebugName("ReorderWithQuantCast");
    }

public:
    mlir::LogicalResult matchAndRewrite(IE::QuantizeCastOp origQuantCastOp,
                                        mlir::PatternRewriter& rewriter) const final;

private:
    Logger _log;
};

mlir::LogicalResult ReorderWithQuantCast::matchAndRewrite(IE::QuantizeCastOp origQuantCastOp,
                                                          mlir::PatternRewriter& rewriter) const {
    auto origReorderOp = origQuantCastOp.getInput().getDefiningOp<IE::ReorderOp>();
    if (origReorderOp == nullptr) {
        return mlir::failure();
    }

    _log.trace("Got reorder at '{0}' -> quantize cast at '{1}' pair", origReorderOp->getLoc(),
               origQuantCastOp->getLoc());

    auto newQuantCastOp = rewriter.create<IE::QuantizeCastOp>(origQuantCastOp->getLoc(), origReorderOp.getInput(),
                                                              origQuantCastOp.getDstElemTypeAttr());

    rewriter.replaceOpWithNewOp<IE::ReorderOp>(origQuantCastOp, newQuantCastOp.getOutput(),
                                               origReorderOp.getDstOrderAttr());
    return mlir::success();
}

//
// ReorderWithPermuteCast
//
//               input                                input
//                 |                                    |
//              Reorder                             PermuteCast
//                 |                                    |
//             PermuteCast            ==>            Reorder
//                 |                                    |
//              Reorder                              Reorder
//                 |                                    |
//               output                               output
//
// No benefit for case that the input is a NCE task as it could fuse mem permute
// Not swap for case that two reorder could not be eliminated and the user of nextReorder is concatOp
//

class ReorderWithPermuteCast final : public mlir::OpRewritePattern<IE::PermuteCastOp> {
public:
    ReorderWithPermuteCast(mlir::MLIRContext* ctx, Logger log)
            : mlir::OpRewritePattern<IE::PermuteCastOp>(ctx), _log(log) {
        setDebugName("ReorderWithPermuteCast");
    }

public:
    mlir::LogicalResult matchAndRewrite(IE::PermuteCastOp origPermuteCastOp,
                                        mlir::PatternRewriter& rewriter) const final;

private:
    Logger _log;
};

// Infer the output logical layout of original permuteCast, which is the same as the new permuteCast
// For example, based on the permutecast output physical layout = NCDHW, and permutecast
// dstOrder: [d0, d4, d1, d2, d3], it could calculate the permutecast logical layout = NDHWC
DimsOrder inferPermuteCastOutLogicalLayout(vpux::DimsOrder origReorderDstOrder,
                                           mlir::AffineMap origPermuteCastDstOrder) {
    auto origPermuteCastOutPerm = origReorderDstOrder.toPermutation();
    const auto order = DimsOrder::fromAffineMap(origPermuteCastDstOrder);
    auto targetPermutation = order.toPermutation();
    auto sourcePermutation = order.toPermutation();

    for (auto pIt = origPermuteCastOutPerm.begin(); pIt != origPermuteCastOutPerm.end(); ++pIt) {
        auto dimPosTargetPermutation = origReorderDstOrder.dimPos(Dim(pIt->ind()));
        sourcePermutation[targetPermutation[dimPosTargetPermutation].ind()] = Dim(pIt->ind());
    }

    return DimsOrder::fromPermutation(sourcePermutation);
}

// Infer the dstOrder of the new permuteCast
// For example, If the new permutecast logical layout = NDHWC, and physical layout = NDHWC
// it could calculate the new permuteCast dstOrder: [d0, d1, d2, d3, d4]
DimsOrder inferPermuteCastDstOrder(IE::ReorderOp origReorderOp, IE::PermuteCastOp origPermuteCastOp,
                                   mlir::MLIRContext* ctx) {
    const auto origReorderDstOrder = DimsOrder::fromAffineMap(origReorderOp.getDstOrder());
    const auto origPermuteCastDstOrderAttr = origPermuteCastOp.getDstOrderAttr();

    auto logicalLayout = inferPermuteCastOutLogicalLayout(origReorderDstOrder, origPermuteCastDstOrderAttr.getValue());

    // Calculate the permutation of new permuteCast
    const auto outputOrder = vpux::DimsOrder::fromValue(origReorderOp.getInput());
    const auto memPerm = vpux::getPermutationFromOrders(logicalLayout, outputOrder, ctx);

    return DimsOrder::fromAffineMap(memPerm);
}

mlir::LogicalResult ReorderWithPermuteCast::matchAndRewrite(IE::PermuteCastOp origPermuteCastOp,
                                                            mlir::PatternRewriter& rewriter) const {
    auto origReorderOp = origPermuteCastOp.getInput().getDefiningOp<IE::ReorderOp>();
    if (origReorderOp == nullptr) {
        return mlir::failure();
    }

    if (!origReorderOp.getResult().hasOneUse() || !origPermuteCastOp.getResult().hasOneUse()) {
        return mlir::failure();
    }

    auto nextReorderOp = mlir::dyn_cast<IE::ReorderOp>(*origPermuteCastOp.getResult().getUsers().begin());
    if (nextReorderOp == nullptr) {
        return mlir::failure();
    }

    // If Reorder is Trivial Permute, will not swap
    if (isTrivialReorder(origReorderOp)) {
        return mlir::failure();
    }

    const auto origOutOrder = DimsOrder::fromValue(origPermuteCastOp.getOutput());
    const auto numDims = checked_cast<unsigned>(origOutOrder.numDims());
    const auto identityMap = mlir::AffineMap::getMinorIdentityMap(numDims, numDims, rewriter.getContext());
    if (origPermuteCastOp.getMemPerm() != identityMap) {
        return mlir::failure();
    }

    // No benefit for case that NCE tasks could fuse mem permute
    auto layerWithPermute = origReorderOp.getInput().getDefiningOp<IE::LayerWithPermuteInterface>();
    if (layerWithPermute != nullptr && layerWithPermute.isSupportedPermutation(origReorderOp)) {
        return mlir::failure();
    }

    // Infer the DstOrder of the new permuteCast
    auto newDstOrder = inferPermuteCastDstOrder(origReorderOp, origPermuteCastOp, rewriter.getContext());
    const auto newDstOrderAttr = mlir::AffineMapAttr::get(newDstOrder.toAffineMap(rewriter.getContext()));
    auto newMemPermAttr = origPermuteCastOp.getMemPermAttr();

    // Not swap in case that the two reorder could not be eliminated and the nextReorder's user is concatOp
    const auto nextReorderOutOrder = DimsOrder::fromAffineMap(nextReorderOp.getDstOrder());
    bool canEliminate = newDstOrder == nextReorderOutOrder;
    for (auto* nextReorderUser : llvm::make_early_inc_range(nextReorderOp.getResult().getUsers())) {
        auto nextConcat = mlir::dyn_cast<IE::ConcatOp>(nextReorderUser);
        if (nextConcat != nullptr && !canEliminate) {
            return mlir::failure();
        }
    }

    _log.trace("Got reorder at '{0}' -> permute cast at '{1}' pair", origReorderOp->getLoc(),
               origPermuteCastOp->getLoc());

    auto newPermuteCastOp = rewriter.create<IE::PermuteCastOp>(origPermuteCastOp->getLoc(), origReorderOp.getInput(),
                                                               newDstOrderAttr, newMemPermAttr);

    rewriter.replaceOpWithNewOp<IE::ReorderOp>(origPermuteCastOp, newPermuteCastOp.getOutput(),
                                               origPermuteCastOp.getDstOrderAttr());
    return mlir::success();
}

//
// ReorderWithConvert
//

class ReorderWithConvert final : public mlir::OpRewritePattern<IE::ConvertOp> {
public:
    ReorderWithConvert(mlir::MLIRContext* ctx, Logger log): mlir::OpRewritePattern<IE::ConvertOp>(ctx), _log(log) {
        setDebugName("ReorderWithConvert");
    }

public:
    mlir::LogicalResult matchAndRewrite(IE::ConvertOp convertOp, mlir::PatternRewriter& rewriter) const final;

private:
    Logger _log;
};

mlir::LogicalResult ReorderWithConvert::matchAndRewrite(IE::ConvertOp convertOp,
                                                        mlir::PatternRewriter& rewriter) const {
    // Note that in this case we replace Convert -> Reorder with Reorder -> Convert
    // This is an opposite behavior, compared to other rewriters
    if (!convertOp.getResult().hasOneUse()) {
        return matchFailed(_log.nest(), rewriter, convertOp, "ConvertOp has more then one user");
    }

    auto origReorderOp = mlir::dyn_cast<IE::ReorderOp>(*convertOp.getResult().getUsers().begin());
    if (origReorderOp == nullptr) {
        return mlir::failure();
    }

    const auto srcType = convertOp.getInput().getType();
    const auto dstElemType = convertOp.getDstElemType();
    if (getElemTypeSize(srcType) >= getElemTypeSize(dstElemType)) {
        return matchFailed(rewriter, convertOp, "Convert doesn't increase data size");
    }

    auto newReorderOp = rewriter.create<IE::ReorderOp>(origReorderOp->getLoc(), convertOp.getInput(),
                                                       origReorderOp.getDstOrderAttr());

    rewriter.replaceOpWithNewOp<IE::ConvertOp>(origReorderOp, origReorderOp.getType(), newReorderOp.getOutput(),
                                               convertOp.getDstElemTypeAttr());

    return mlir::success();
}

// Search op on the consumer chain(bypass view like operations), until target operation is found or reach the last
// consumer.
// Return mlir::Operation if target op is found, otherwise return mlir::failure().
mlir::FailureOr<mlir::Operation*> searchOpConsumers(mlir::Operation* op,
                                                    const std::function<bool(mlir::Operation*)>& isTargetOpFound) {
    if (op == nullptr) {
        return mlir::failure();
    }

    for (auto user : op->getUsers()) {
        mlir::Operation* operation = user;
        while (operation) {
            if (isTargetOpFound(operation)) {
                return operation;
            } else if (IE::isPureViewOp(operation) && operation->hasOneUse()) {
                operation = *(operation->getUsers().begin());
                continue;
            } else {
                break;
            }
        }
    }
    return mlir::failure();
}

mlir::FailureOr<mlir::Operation*> getConvertOrReturnOpConsumer(mlir::Operation* op) {
    std::function<bool(mlir::Operation*)> isConvertOrReturnOpFound = [](mlir::Operation* op) -> bool {
        return mlir::isa<IE::ConvertOp, mlir::func::ReturnOp>(op);
    };

    return searchOpConsumers(op, isConvertOrReturnOpFound);
}

mlir::FailureOr<mlir::Operation*> getReturnOpConsumer(mlir::Operation* op) {
    std::function<bool(mlir::Operation*)> isReturnOpFound = [](mlir::Operation* op) -> bool {
        return mlir::isa<mlir::func::ReturnOp>(op);
    };

    return searchOpConsumers(op, isReturnOpFound);
}

bool doesConvertOpIncreaseElemSize(IE::ConvertOp convertOp) {
    const auto srcType = convertOp.getInput().getType();
    const auto dstElemType = convertOp.getDstElemType();
    return getElemTypeSize(srcType) <= getElemTypeSize(dstElemType);
}

//
// ReorderWithLayer
//

class ReorderWithLayer final : public mlir::OpInterfaceRewritePattern<IE::LayoutInfoOpInterface> {
public:
    ReorderWithLayer(mlir::MLIRContext* ctx, Logger log, const bool seOpsEnabled, const bool seTransposedConvEnabled)
            : mlir::OpInterfaceRewritePattern<IE::LayoutInfoOpInterface>(ctx),
              _log(log),
              _seOpsEnabled(seOpsEnabled),
              _seTransposedConvEnabled(seTransposedConvEnabled) {
        setDebugName("ReorderWithLayer");
    }

public:
    mlir::LogicalResult matchAndRewrite(IE::LayoutInfoOpInterface layerOp, mlir::PatternRewriter& rewriter) const final;

private:
    Logger _log;
    bool _seOpsEnabled;
    bool _seTransposedConvEnabled;
};

mlir::LogicalResult ReorderWithLayer::matchAndRewrite(IE::LayoutInfoOpInterface layerOp,
                                                      mlir::PatternRewriter& rewriter) const {
    if (mlir::isa<IE::ReorderOp>(layerOp)) {
        return mlir::failure();
    }

    _log.trace("Got layer operation '{0}' at '{1}'", layerOp->getName(), layerOp->getLoc());

    auto argReorderOp = layerOp->getOperand(0).getDefiningOp<IE::ReorderOp>();
    if (argReorderOp == nullptr) {
        return mlir::failure();
    }

    // Skip reorder propagation for below cases:
    // 1.ReorderOp's consumers are pure view like ops with ReturnOp
    //   e.g.Reorder->AffineReshape->PermuteCast->QuantizeCast->ReturnOp
    // 2.ReorderOp's consumers are pure view like ops with ConvertOp and ReturnOp.
    //   Additionally ConvertOp is increasing element type size.
    //   e.g.Reorder->AffineReshape->ConvertOp(F16->F32)->AffineReshape->PermuteCast->QuantizeCast->ReturnOp
    // 3.ReorderOp's consumers is tileOp and the propagation will lead a low efficient layout for tileOp.
    if (auto tileOp = mlir::dyn_cast<IE::TileOp>(&layerOp)) {
        if (!isBeneficialReorderFuse(*tileOp)) {
            if (!isBeneficialSwitch(*tileOp, DimsOrder::fromValue(argReorderOp.getOutput()),
                                    DimsOrder::fromValue(argReorderOp.getInput()))) {
                return mlir::failure();
            }
        }
    }
    auto getConsumerResult = getConvertOrReturnOpConsumer(argReorderOp);
    if (!mlir::failed(getConsumerResult)) {
        auto convertOrReturnOp = getConsumerResult.value();
        if (mlir::isa<mlir::func::ReturnOp>(convertOrReturnOp)) {
            return mlir::failure();
        } else if (mlir::isa<IE::ConvertOp>(convertOrReturnOp)) {
            auto convertOp = mlir::dyn_cast<IE::ConvertOp>(convertOrReturnOp);
            bool convertOpHasReturnConsumer = !mlir::failed(getReturnOpConsumer(convertOp));
            if (convertOpHasReturnConsumer && doesConvertOpIncreaseElemSize(convertOp)) {
                return mlir::failure();
            }
        } else {
            VPUX_THROW("Unexpected operation '{0}' at '{1}'", convertOrReturnOp->getName(),
                       convertOrReturnOp->getLoc());
        }
    }

    const auto propagatingOrder = DimsOrder::fromValue(argReorderOp.getInput());

    // Propagate first input layout and infer layout info
    auto orderInfo = layerOp.getLayoutInfo();
    orderInfo.setInput(0, propagatingOrder);
    layerOp.inferLayoutInfo(orderInfo, _seOpsEnabled, _seTransposedConvEnabled);
    if (orderInfo.getInput(0) != propagatingOrder) {
        return matchFailed(_log.nest(), rewriter, layerOp, "Layer doesn't support propagating order {0}",
                           propagatingOrder);
    }

    // Check if additional reorders for other inputs are needed
    for (auto ind : irange<size_t>(1, orderInfo.getNumInputs())) {
        const auto input = layerOp->getOperand(checked_cast<uint32_t>(ind));
        const auto order = DimsOrder::fromValue(input);
        const auto isConstInput = mlir::isa_and_nonnull<Const::DeclareOp>(input.getDefiningOp());
        const auto isReorderInput = mlir::isa_and_nonnull<IE::ReorderOp>(input.getDefiningOp());
        const auto canAddTrivialReorder =
                isTrivialReorder(order, orderInfo.getInput(checked_cast<uint32_t>(ind)), getShape(input));

        if (order != orderInfo.getInput(ind) && !isConstInput && !isReorderInput && !canAddTrivialReorder) {
            return matchFailed(_log.nest(), rewriter, layerOp, "Non-constant inputs require additional Reorders");
        }
    }

    rewriter.startRootUpdate(layerOp);

    _log.nest(1).trace("Remove Reorder before the first input");
    layerOp->getOpOperand(0).set(argReorderOp.getInput());

    const auto inputs = layerOp->getOpOperands();
    for (auto i : irange<size_t>(1, inputs.size())) {
        auto& input = inputs[i];

        const auto curOrder = DimsOrder::fromValue(input.get());
        const auto supportedOrder = orderInfo.getInput(i);

        _log.nest(1).trace("Process input #{0}", i);
        if (curOrder != supportedOrder) {
            insertReorderForInput(layerOp, input, supportedOrder, rewriter, _log.nest());
        }

        if (curOrder != propagatingOrder && mlir::isa<IE::PowerOp>(layerOp.getOperation())) {
            insertReorderForInput(layerOp, input, propagatingOrder, rewriter, _log.nest());
        }
    }

    const auto outputs = layerOp->getOpResults();
    for (auto i : irange(outputs.size())) {
        auto output = outputs[i];

        const auto curOrder = DimsOrder::fromValue(output);
        const auto supportedOrder = orderInfo.getOutput(i);

        _log.nest(1).trace("Process output #{0}", i);
        if (curOrder != supportedOrder) {
            changeDimsOrder(output, supportedOrder, _log.nest());
            insertReorderForOutput(layerOp, output, curOrder, rewriter, _log.nest());
        }
    }

    rewriter.finalizeRootUpdate(layerOp);

    return mlir::success();
}

//
// ReorderWithAssign
//

class ReorderWithAssign final : public mlir::OpRewritePattern<IE::AssignOp> {
public:
    ReorderWithAssign(mlir::MLIRContext* ctx, const mlir::DenseSet<llvm::StringRef> inputSet, Logger log)
            : mlir::OpRewritePattern<IE::AssignOp>(ctx), _assignNameSetToOptimize(inputSet), _log(log) {
        setDebugName("ReorderWithAssign");
    }

    mlir::LogicalResult matchAndRewrite(IE::AssignOp origAssignOp, mlir::PatternRewriter& rewriter) const final;

private:
    mlir::DenseSet<llvm::StringRef> _assignNameSetToOptimize;
    Logger _log;
};

// Remove reorder connected to assign op, and change the layout of assign op
mlir::LogicalResult ReorderWithAssign::matchAndRewrite(IE::AssignOp origAssignOp,
                                                       mlir::PatternRewriter& rewriter) const {
    _log.trace("[{0}] Got ReorderWithAssign layer at '{1}'", getDebugName(), origAssignOp->getLoc());

    if (!_assignNameSetToOptimize.count(origAssignOp.getName())) {
        return mlir::failure();
    }

    auto prevOp = origAssignOp.getInput().getDefiningOp();

    if (!prevOp->getResult(0).hasOneUse()) {
        return matchFailed(_log.nest(), rewriter, prevOp, "prev ReorderOp has more then one user");
    }

    if (!mlir::isa_and_nonnull<IE::ReorderOp>(prevOp)) {
        return mlir::failure();
    }

    auto prevOpInputDimsOrder = DimsOrder::fromValue(prevOp->getOperand(0));
    vpux::changeDimsOrder(origAssignOp.getInput(), prevOpInputDimsOrder, _log);
    vpux::changeDimsOrder(origAssignOp.getOutput(), prevOpInputDimsOrder, _log);
    rewriter.replaceOp(prevOp, prevOp->getOperand(0));
    return mlir::success();
}

//
// ReorderWithReadValue
//

class ReorderWithReadValue final : public mlir::OpRewritePattern<IE::ReadValueOp> {
public:
    ReorderWithReadValue(mlir::MLIRContext* ctx, const mlir::DenseSet<llvm::StringRef> inputSet, Logger log)
            : mlir::OpRewritePattern<IE::ReadValueOp>(ctx), _readValueNameSetToOptimize(inputSet), _log(log) {
        setDebugName("ReorderWithReadValue");
    }

    mlir::LogicalResult matchAndRewrite(IE::ReadValueOp origReadValueOp, mlir::PatternRewriter& rewriter) const final;

private:
    mlir::DenseSet<llvm::StringRef> _readValueNameSetToOptimize;
    Logger _log;
};

// Revert the order between read value and reorder to remove reorders connected to read value op
mlir::LogicalResult ReorderWithReadValue::matchAndRewrite(IE::ReadValueOp origReadValueOp,
                                                          mlir::PatternRewriter& rewriter) const {
    _log.trace("[{0}] Got ReorderWithReadValue layer at '{1}'", getDebugName(), origReadValueOp->getLoc());

    if (!_readValueNameSetToOptimize.count(origReadValueOp.getName())) {
        return mlir::failure();
    }

    if (!origReadValueOp.getOutput().hasOneUse()) {
        return matchFailed(_log.nest(), rewriter, origReadValueOp, "ReadValue has more then one user");
    }

    auto origReorderOp = mlir::dyn_cast<IE::ReorderOp>(*origReadValueOp.getOutput().getUsers().begin());

    if (origReorderOp == nullptr) {
        return mlir::failure();
    }

    // Note that in this case we replace Declare -> ReadValue -> Reorder with Declare -> Reorder -> ReadValue,
    // Then Declare -> Reorder -> ReadValue will be changed to Declare -> ReadValue
    auto newReorderOp = rewriter.create<IE::ReorderOp>(origReorderOp->getLoc(), origReadValueOp.getInput(),
                                                       origReorderOp.getDstOrderAttr());

    rewriter.replaceOpWithNewOp<IE::ReadValueOp>(origReorderOp, newReorderOp.getOutput(), origReadValueOp.getName());
    // erase readvalue ops which has no more nodes next
    rewriter.eraseOp(origReadValueOp);

    return mlir::success();
}

//
// OptimizeReordersPass
//

class OptimizeReordersPass final : public IE::OptimizeReordersBase<OptimizeReordersPass> {
public:
    explicit OptimizeReordersPass(const bool seOpsEnabled, const bool seTransposedConvEnabled, Logger log)
            : _seOpsEnabled(seOpsEnabled), _seTransposedConvEnabled(seTransposedConvEnabled) {
        Base::initLogger(log, Base::getArgumentName());
    }

private:
    void safeRunOnFunc() final;

    mlir::DenseSet<llvm::StringRef> getReadValueAndAssignPairs(mlir::func::FuncOp func, Logger log);

private:
    bool _seOpsEnabled;
    bool _seTransposedConvEnabled;
};

mlir::DenseSet<llvm::StringRef> OptimizeReordersPass::getReadValueAndAssignPairs(mlir::func::FuncOp func, Logger log) {
    // traverse to get all read value and assign ops, and record them with reorders connected to
    mlir::DenseMap<llvm::StringRef, DimsOrder> readValueMap;
    mlir::DenseMap<llvm::StringRef, DimsOrder> assignMap;

    func->walk([&](IE::ReadValueOp readValueOp) {
        auto nextOp = *readValueOp.getOutput().getUsers().begin();
        if (mlir::isa_and_nonnull<IE::ReorderOp>(nextOp) && readValueOp.getResult().hasOneUse()) {
            // Only if readValue has one user, i.e. Reorder Op, the convert is legal to happen
            log.trace("Found Read Value Operation with Reorder Op'{0}' ", readValueOp->getLoc());
            auto nextOpResultDimsOrder = DimsOrder::fromValue(nextOp->getResult(0));
            readValueMap.insert({readValueOp.getName(), nextOpResultDimsOrder});
        }
    });

    func->walk([&](IE::AssignOp assignOp) {
        auto prevOp = assignOp.getInput().getDefiningOp();
        if (mlir::isa_and_nonnull<IE::ReorderOp>(prevOp) && prevOp->getResult(0).hasOneUse()) {
            // Only if prev Reorder Op has one user, i.e. Assign Op, the convert is legal to happen
            log.trace("Found Assign Operation with Reorder Op'{0}' ", assignOp->getLoc());
            auto prevOpInputDimsOrder = DimsOrder::fromValue(prevOp->getOperand(0));
            assignMap.insert({assignOp.getName(), prevOpInputDimsOrder});
        }
    });

    mlir::DenseSet<llvm::StringRef> readValueAndAssignCommonPairs;
    for (auto ex : readValueMap) {
        if (assignMap[ex.first] == ex.second) {
            readValueAndAssignCommonPairs.insert(ex.first);
        }
    }

    return readValueAndAssignCommonPairs;
}

void OptimizeReordersPass::safeRunOnFunc() {
    auto& ctx = getContext();
    (void)_seTransposedConvEnabled;

    mlir::RewritePatternSet patterns(&ctx);
    patterns.add<ReorderWithShapeChange<IE::ReshapeOp>>(&ctx, _log);
    patterns.add<ReorderWithShapeChange<IE::AffineReshapeOp>>(&ctx, _log);
    patterns.add<ReorderWithShapeChange<IE::ShapeCastOp>>(&ctx, _log);
    patterns.add<ReorderWithSubView>(&ctx, _log);
    patterns.add<ReorderWithExpand>(&ctx, _log);
    patterns.add<ReorderWithSplit>(&ctx, _log);
    patterns.add<ReorderWithConcat>(&ctx, _log);
    patterns.add<ReorderWithQuantCast>(&ctx, _log);
    patterns.add<ReorderWithTile>(&ctx, _log);
    patterns.add<ReorderWithLayer>(&ctx, _log, _seOpsEnabled, _seTransposedConvEnabled);
    patterns.add<ReorderWithPermuteCast>(&ctx, _log);
    IE::ReorderOp::getCanonicalizationPatterns(patterns, &ctx);

    auto func = getOperation();
    if (mlir::failed(mlir::applyPatternsAndFoldGreedily(func, std::move(patterns), getDefaultGreedyRewriteConfig()))) {
        signalPassFailure();
        return;
    }

    auto readValueAndAssignCommonPairs = getReadValueAndAssignPairs(func, _log);
    mlir::RewritePatternSet rvaPatterns(&ctx);
    rvaPatterns.add<ReorderWithAssign>(&ctx, readValueAndAssignCommonPairs, _log);
    rvaPatterns.add<ReorderWithReadValue>(&ctx, readValueAndAssignCommonPairs, _log);
    IE::ReorderOp::getCanonicalizationPatterns(rvaPatterns, &ctx);

    if (mlir::failed(
                mlir::applyPatternsAndFoldGreedily(func, std::move(rvaPatterns), getDefaultGreedyRewriteConfig()))) {
        signalPassFailure();
    }

    mlir::RewritePatternSet cleanupPatterns(&ctx);
    cleanupPatterns.add<ReorderWithConvert>(&ctx, _log);
    cleanupPatterns.add<ReorderWithExpandSlice>(&ctx, _log);
    IE::ReorderOp::getCanonicalizationPatterns(cleanupPatterns, &ctx);

    if (mlir::failed(mlir::applyPatternsAndFoldGreedily(func, std::move(cleanupPatterns),
                                                        getDefaultGreedyRewriteConfig()))) {
        signalPassFailure();
    }
}

}  // namespace

//
// createOptimizeReordersPass
//

std::unique_ptr<mlir::Pass> vpux::IE::createOptimizeReordersPass(const bool seOpsEnabled,
                                                                 const bool seTransposedConvEnabled, Logger log) {
    return std::make_unique<OptimizeReordersPass>(seOpsEnabled, seTransposedConvEnabled, log);
}
