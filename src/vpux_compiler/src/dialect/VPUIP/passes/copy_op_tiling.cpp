//
// Copyright (C) 2022 Intel Corporation.
// SPDX-License-Identifier: Apache 2.0
//

#include "vpux/compiler/dialect/VPUIP/ops.hpp"
#include "vpux/compiler/dialect/VPUIP/passes.hpp"
#include "vpux/compiler/dialect/VPUIP/utils.hpp"
#include "vpux/compiler/utils/rewriter.hpp"
#include "vpux/compiler/utils/types.hpp"
#include "vpux/utils/core/numeric.hpp"

#include <mlir/IR/PatternMatch.h>

using namespace vpux;

namespace {

Byte getDmaSize(VPUIP::CopyOp copyOp) {
    const auto inputShape = getShape(copyOp.getInput());
    const auto outputShape = getShape(copyOp.getOutput());
    VPUX_THROW_UNLESS(inputShape == outputShape,
                      "CopyOpTiling: Copy node's input and output have different shapes: {0} vs {1}", inputShape,
                      outputShape);

    // Sparse data is composed of multiple buffers which will later get ungrouped into individual Copy operations
    // Therefore, the maximum buffer size is selected for tiling
    if (auto sparseInput = copyOp.getInput().getType().dyn_cast<VPUIP::SparseBufferType>()) {
        auto dataSize = sparseInput.getData().cast<vpux::NDTypeInterface>().getCompactAllocSize();
        auto sparsityMapSize =
                (sparseInput.getSparsityMap() != nullptr)
                        ? sparseInput.getSparsityMap().cast<vpux::NDTypeInterface>().getCompactAllocSize()
                        : Byte(0);
        auto seTableSize =
                (sparseInput.getStorageElementTable() != nullptr)
                        ? sparseInput.getStorageElementTable().cast<vpux::NDTypeInterface>().getCompactAllocSize()
                        : Byte(0);
        return std::max({dataSize, sparsityMapSize, seTableSize});
    }

    return static_cast<Byte>(getCompactSize(copyOp.getInput()));
}

bool isLegalCopyOp(VPUIP::CopyOp copyOp) {
    // Distributed type is currently not needed as large DMAs to CMX are already handled by previous tiling pass and
    // size of CMX is nevertheless smaller then DMA limit
    if (mlir::dyn_cast<VPUIP::NCEClusterTilingOp>(copyOp->getParentOp()) != nullptr) {
        return true;
    }

    // If tensor size is greater than DMA_LIMIT its no longer legal operation
    if (getDmaSize(copyOp) > VPUIP::DMA_LIMIT) {
        return false;
    }

    return !VPUIP::isSplitNeededForLargePlanesNum(copyOp);
};

//
// CopyOpTilingPass
//

class CopyOpTilingPass final : public VPUIP::CopyOpTilingBase<CopyOpTilingPass> {
public:
    explicit CopyOpTilingPass(Logger log) {
        Base::initLogger(log, Base::getArgumentName());
    }

private:
    void safeRunOnFunc() final;
};

//
// CopyOpTiling
//

// Splits large CopyOps into a bunch of smaller ones to fit DMA capabilities
class CopyOpTiling final : public mlir::OpRewritePattern<VPUIP::CopyOp> {
public:
    CopyOpTiling(mlir::MLIRContext* ctx, Logger log, VPU::ArchKind arch, bool allowRecursiveSplit)
            : mlir::OpRewritePattern<VPUIP::CopyOp>(ctx),
              _log(log),
              _arch(arch),
              _allowRecursiveSplit(allowRecursiveSplit) {
    }

public:
    mlir::LogicalResult matchAndRewrite(VPUIP::CopyOp origOp, mlir::PatternRewriter& rewriter) const final;

private:
    SmallVector<mlir::Value> createTiles(VPUIP::CopyOp origOp, mlir::PatternRewriter& rewriter) const;

    Logger _log;
    VPU::ArchKind _arch;
    const bool _allowRecursiveSplit;
};

SmallVector<mlir::Value> CopyOpTiling::createTiles(VPUIP::CopyOp origOp, mlir::PatternRewriter& rewriter) const {
    const auto origInputShape = getShape(origOp.getInput());

    const auto fullCopySize = getDmaSize(origOp);

    auto tileDim = VPUIP::getCopyDMATilingDimForLargeSize(origOp);
    if (VPUIP::isSplitNeededForLargePlanesNum(origOp)) {
        tileDim = VPUIP::getCopyDMATilingDimForLargePlaneNum(origOp);
    }

    // We cannot _just_ divide the fullCopySize by sizeLimit to get the number of tiles required
    // Example: let fullCopySize=48MB, sizeLimit=16MB and IFM.C=4, then it would be 48/16=3 tiles, but it's obviously
    //          impossible to split 4 channels into 3 tiles each of those would fit the limits
    const auto numPlanesOfFullShape = origInputShape[tileDim];
    const auto singlePlaneSize = fullCopySize / numPlanesOfFullShape;
    //  The number of planes DMA could process within one tile. In case of small spatial dimensions of tensor (e.g.
    // 1x2048x8x8) it can exceed CMX_DMA_MAX_NUM_PLANES, so it's necessary to limit this value
    const auto maxNumPlanes = VPUIP::getMaxNumberPlanes(_arch);
    int64_t desiredPlanesPerTileAmount = (VPUIP::DMA_LIMIT.count() / singlePlaneSize.count());
    if (desiredPlanesPerTileAmount == 0 && _allowRecursiveSplit) {
        desiredPlanesPerTileAmount = 1;
    }
    VPUX_THROW_UNLESS(desiredPlanesPerTileAmount != 0,
                      "Couldn't split a CopyOp at '{0}' with single plane size greater than DMA_LIMIT",
                      origOp->getLoc());

    const auto numPlanesPerTile = std::min(desiredPlanesPerTileAmount, maxNumPlanes);

    SmallVector<mlir::Value> concatInputs;
    auto currentOffset = SmallVector<int64_t>(origInputShape.size(), 0);
    auto currentTileShapeVector = to_small_vector(origInputShape);
    auto planesLeftToCopy = numPlanesOfFullShape;
    for (int64_t tileIdx = 0; planesLeftToCopy > 0; ++tileIdx) {
        // Get the proper shape and a new location for the tile
        const auto tileLoc = appendLoc(origOp->getLoc(), "tile {0}", tileIdx);
        currentTileShapeVector[tileDim.ind()] = std::min(numPlanesPerTile, planesLeftToCopy);

        // Create the operations for it
        auto inputSubView =
                rewriter.create<VPUIP::SubViewOp>(tileLoc, origOp.getInput(), currentOffset, currentTileShapeVector);
        auto outputSubView = rewriter.create<VPUIP::SubViewOp>(tileLoc, origOp.getOutputBuff(), currentOffset,
                                                               currentTileShapeVector);
        auto copyTile = rewriter.create<VPUIP::CopyOp>(tileLoc, inputSubView.getResult(), outputSubView.getResult());

        concatInputs.push_back(copyTile.getOutput());
        _log.nest().trace("Created tile #{0} for {1} planes that requires {2}", tileIdx,
                          currentTileShapeVector[tileDim.ind()], getDmaSize(copyTile));

        // Take into account the part of the original tensor covered with the newly created tile
        planesLeftToCopy -= currentTileShapeVector[tileDim.ind()];
        currentOffset[tileDim.ind()] += currentTileShapeVector[tileDim.ind()];
    }

    VPUX_THROW_UNLESS(planesLeftToCopy == 0 && currentOffset[tileDim.ind()] == numPlanesOfFullShape,
                      "CopyOpTiling: a part of the original shape was not covered by Copy tiles");

    return concatInputs;
}

mlir::LogicalResult CopyOpTiling::matchAndRewrite(VPUIP::CopyOp origOp, mlir::PatternRewriter& rewriter) const {
    _log.trace("Found Copy Operation '{0}'", origOp->getLoc());
    // In case of recursive legalization we want to split only illegal operations with striding level less than max
    // available and leave max level DMAs to be handled by main rewriter
    if (_allowRecursiveSplit) {
        const int64_t maxStridingLevel = VPUIP::getMaxStridingLevel(VPU::getArch(origOp));
        const bool hasValidStridingLevel = VPUIP::getStridingLevel(origOp->getOperand(0)) < maxStridingLevel &&
                                           VPUIP::getStridingLevel(origOp->getResult(0)) < maxStridingLevel;
        if (isLegalCopyOp(origOp) || !hasValidStridingLevel) {
            return mlir::failure();
        }
    }

    const auto concatInputs = createTiles(origOp, rewriter);

    rewriter.replaceOpWithNewOp<VPUIP::ConcatViewOp>(origOp, concatInputs, origOp.getOutputBuff());

    return mlir::success();
}

//
// safeRunOnFunc
//

/*
For two strides DMA in VPU, it will be implemented through plane.
If a two strides DMA do this date movement:
123 456 789
  ||
  \/                 | plane |
 1XX2XX3XX XXXXXXXXX 4XX5XX6XX XXXXXXXXX 7XX8XX9XX XXXXXXXXX
 |  |                |                   |
 stride              |                   |
                     |<-  plane stride ->|
The higher dim stride is implemented through plane stride.

So if the higher dim with stride size large than CMX_DMA_MAX_NUM_PLANES, we need tile the copy on this dim
*/

void CopyOpTilingPass::safeRunOnFunc() {
    auto& ctx = getContext();
    auto func = getOperation();
    auto module = func->getParentOfType<mlir::ModuleOp>();
    const auto arch = VPU::getArch(module);
    // First try to legalize recursively. Some operations may have shapes, which can't be resolved by single axis split,
    // so try to legalize them recursively, for example: 3x1x4000x4000 to 3 DMAs with shape 1x1x4000x4000 and then split
    // each of them separatly to satisfy numPlanes and DMA_LIMIT requirements
    {
        mlir::RewritePatternSet patterns(&ctx);
        patterns.add<CopyOpTiling>(&ctx, _log, arch, /*allowRecursiveSplit=*/true);
        if (mlir::failed(
                    mlir::applyPatternsAndFoldGreedily(func, std::move(patterns), getDefaultGreedyRewriteConfig()))) {
            signalPassFailure();
            return;
        }
    }
    // After all, some DMAs may be illegal. This conversion confirms that this isn't possible and stops compilation.
    {
        mlir::ConversionTarget target(ctx);
        target.addDynamicallyLegalOp<VPUIP::CopyOp>(isLegalCopyOp);

        mlir::RewritePatternSet patterns(&ctx);
        patterns.add<CopyOpTiling>(&ctx, _log, arch, /*allowRecursiveSplit=*/false);

        // The new operations added by CopyOpTiling pattern:
        target.addLegalOp<VPUIP::SubViewOp>();
        target.addLegalOp<VPUIP::ConcatViewOp>();

        if (mlir::failed(mlir::applyPartialConversion(getOperation(), target, std::move(patterns)))) {
            signalPassFailure();
        }
    }
}

}  // namespace

//
// createCopyOpTilingPass
//

std::unique_ptr<mlir::Pass> vpux::VPUIP::createCopyOpTilingPass(Logger log) {
    return std::make_unique<CopyOpTilingPass>(log);
}
