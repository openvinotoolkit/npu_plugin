# How to debug

The compiler offers a number of debug capabilities. In order to benefit from all of them, it is recommended to use a Debug build with the `DEVELOPER_BUILD` flag enabled (the `-DENABLE_DEVELOPER_BUILD=ON` CMake option).

## Logs

The project offers a logging functionality, which different levels of verbosity (from traces to fatal errors) - see the `Logger` class for more information. During compilation, these logs can be printed by making use of the `IE_NPU_LOG_FILTER` environment variable.

The majority of the logs have a name which can be used for filtering. For passes, the name corresponds to the pass argument name (e.g. `convert-layers-to-VPUIP`). This variable is also compatible with POSIX Regex, which allows capturing more than one pass. Examples of values for the variable:

```sh
export IE_NPU_LOG_FILTER=convert-layers-to-VPUIP
export IE_NPU_LOG_FILTER=convert-layers-to-VPU.*
export IE_NPU_LOG_FILTER="convert-layers-to-VPU|convert-layers-to-VPUIP"
```

The variable can be used with applications which follow the normal compilation flow (e.g. `compile_tool`), as well as tools such as `vpux-opt`.

### Pass Timings

Logs are also available for displaying the duration per-pass. These logs are printed at the `INFO` level and can be enabled with:

```sh
export IE_NPU_LOG_FILTER=vpux-compiler
```

The moment a pass starts and ends will be printed, along with a timestamp. At the end of the compilation, a full report is also printed which includes:
- the duration of each pass
- the percentage of time spent in each pass, relative to the entire compilation
- the total compilation time

## IR Printing

One of the most useful debug features of MLIR is by printing the Intermediate Representation (IR) of a model. During compilation, the printing can be done before or after passes and can be controlled using the following variables:

- `IE_NPU_IR_PRINTING_FILTER`: accepts a POSIX Regex filter which describes what passes should have their IR printed
    - examples:
        - `export IE_NPU_IR_PRINTING_FILTER=ConvertLayersToVPUIP`
        - `export IE_NPU_IR_PRINTING_FILTER="InitCompiler|ConvertLayers.*"`
    - by default, it will print to stdout the IRs after the specified passes

- `IE_NPU_IR_PRINTING_ORDER`: controls whether to print the IRs before or after the passes (case-insensitive)
    - `export IE_NPU_IR_PRINTING_ORDER=before` - print IRs before the selected passes
    - `export IE_NPU_IR_PRINTING_ORDER=before_after` - print IRs before and after the selected passes
    - `export IE_NPU_IR_PRINTING_ORDER=after` (default) - print IRs after the selected passes

- `IE_NPU_IR_PRINTING_FILE`: prints the IRs in the file specified in this variable, instead of stdout
    - example: `export IE_NPU_IR_PRINTING_FILE=dump.mlir`

- `IE_NPU_PRINT_FULL_IR`: controls the scope of printing
    - `export IE_NPU_PRINT_FULL_IR=0` (default) - only the affected scope will be printed (e.g. only the main Function of the IR, without the parent Module)
    - `export IE_NPU_PRINT_FULL_IR=1` - the entire IR will be printed, including the parent Module operation (this mode disables MLIR multi-threading)

- `IE_NPU_PRINT_FULL_CONSTANT`: controls whether to print large constants
    - `export IE_NPU_PRINT_FULL_CONSTANT=0` (default) - avoids printing constants whose number of elements is larger than the upper limit (by default 16)
    - `export IE_NPU_PRINT_FULL_CONSTANT=1` - prints the entire content of all constants, regardless of their size
        - this mode is useful when a printed IR is intended to be used for further execution (e.g. running another pass on it), as it cannot be parsed without the full constants

- `IE_NPU_PRINT_HEX_CONSTANT`: controls whether to allow printing constants as hex values
    - `export IE_NPU_PRINT_HEX_CONSTANT=0` - prints the individual values of the constants in a human-readable format
    - `export IE_NPU_PRINT_HEX_CONSTANT=1` (default) - prints the values of the constants as hex values

- `IE_NPU_PRINT_DEBUG_INFO`: controls whether to print the locations of the operations into the IRs
    - `export IE_NPU_PRINT_DEBUG_INFO=0` (default) - no locations will be printed into the IR
    - `export IE_NPU_PRINT_DEBUG_INFO=1` - locations will be printed for each operation
        - this is useful in order to cross-reference an operation from the IR with the layers found in the original OpenVINO IR used for compilation; for each operation, the first string in the location should correspond with the name of the original OpenVINO layer

## vpux-opt and vpux-translate

These tools can be used to call specific parts of the compiler (frontend, backend, passes) from the command-line.

### vpux-translate

`vpux-translate` allows calling the frontend and backend of the compiler. For example:

- importing OpenVINO IR into IE dialect IR: `vpux-translate --vpu-arch=VPUX37XX --import-IE <path to xml> -o <MLIR file name>`
- exporting VPUIP dialect IR into GraphFile blob: `vpux-translate --vpu-arch=VPUX37XX --export-VPUIP <path to MLIR file> -o <graph blob file name>`

The full list of supported frontends and backends can be found in [vpux-translate.cpp](../../../../tools/vpux-translate/vpux-translate.cpp).

The rest of the options can be found by calling `vpux-translate --help`.

### vpux-opt

`vpux-opt` can be used to call individual passes or pipelines over IRs. For example:

```sh
# Call the ConvertLayersToVPU pass over the input IR found in the file
vpux-opt --vpu-arch=VPUX37XX --convert-layers-to-VPU <MLIR file name>

# Call the ExpandActivationChannels and Canonicalizer passes over the IR
vpux-opt --vpu-arch=VPUX37XX --expand-activation-channels --canonicalizer <MLIR file name>

# Call the LowPrecision pipeline over the IR
vpux-opt --vpu-arch=VPUX37XX --low-precision <MLIR file name>
```

The tool offers some features which can help in debugging the target code:

- `-debug-only=dialect-conversion` - prints a trace of all the changes attempted or done for conversion patterns (e.g. legalization checks for operations, attempted pattern matches, rewriter actions such as insertions, replacements etc.)
- `--mlir-elide-elementsattrs-if-larger=<uint>` - avoid printing constants whose number of elements is larger than the given integer
- `--mlir-print-ir-after-failure` - prints the entire IR which causes a failure to occur (e.g. when a verifier fails)
    - has multiple variations for printing before or after specific passes, all passes or all changes (`--mlir-print-ir-after=<pass-arg>`, `--mlir-print-ir-after-all`, `--mlir-print-ir-after-change`, `--mlir-print-ir-before=<pass-arg>`, `--mlir-print-ir-before-all`)
- `--mlir-print-op-generic` - prints operations using the generic printer instead of the custom one; can be useful in some situations, such as if the custom printer crashes
- `--mlir-print-debuginfo` - include locations into the printed IR
- `--mlir-print-value-users` - prints the users of a value in a comment
- `--verify-each=0` - avoid running verifiers, if their failures prevent the printing of the IR

The rest of the options can be found by calling `vpux-opt --help`.

### Compiling a model using vpux-translate & vpux-opt

The tools can be used to perform a full compilation of a model:

```sh
# Import an OpenVINO IR into IE dialect
./vpux-translate --vpu-arch=VPUX37XX --import-IE <path to OV IR> -o net.mlir

# Call the DefaultHWMode pipeline over the imported IR
./vpux-opt --vpu-arch=VPUX37XX --default-hw-mode net.mlir -o net_out.mlir

# Export the final IR into a GraphFile blob
./vpux-translate --vpu-arch=VPUX37XX --export-VPUIP net_out.mlir > net.blob
```

Since each pass or pipeline can be specified individually, the user can have full control over the calling order of the passes if that is necessary. Options such as `--mlir-print-debuginfo` can also be included for both tools to also track the changes done to the original layers.

## IR Visualization using Dot Graph

The compiler contains a pass which can generate a Dot Graph representation of the IR, called `PrintDot`. It can be used with the following methods:

- Using the `IE_NPU_PRINT_DOT` environment variable (applicable for `DEVELOPER_BUILD`)
    - the variable accepts the name of the pass whose output IR will be represented as a graph (`pass`), as well as the name of the dot file that will contain it (`output`)
    - multiple passes can be covered by separating them using commas
    - examples:
        - `export IE_NPU_PRINT_DOT="output=temp.dot pass=OptimizeAsyncDeps"`
        - `export IE_NPU_PRINT_DOT="output=temp.dot pass=OptimizeAsyncDeps,output=temp2.dot pass=AddBuffersForNetResults"`

- Using `vpux-opt` with the `--print-dot` argument
  - example: `vpux-opt [target passes] --print-dot="output=temp.dot"`

- Using the compiler pipeline, by manually adding the `PrintDot` pass where desired and rebuilding the project
  - example: `pm.addPass(createPrintDot(<FileName>, <Options>));`

**Notes**
- By default, declarations and constants are not included. To include them, add `print-declarations=true and print-const=true` to the pass options.
- The `xdot` application can be used to visualize the dot graph. For big networks however, the application may fail to show the graph. The size of the graph can be reduced by specifying which operations should be included, with the `start-after` & `stop-before` pass options. They should be configured with the exact names of the operation from the compiler IR.
    - example: `start-after=pool2 stop-before=conv4/WithoutBiases`

## Crash Reproducer

MLIR offers a feature which allows the creation of reproducers in the event of a crash or pass failure. These reproducers will contain the input IR to the failing pass / pipeline as well as the instructions for reproducing it. Executing a reproducer using `vpux-opt` should then result in the same error. This is a very useful feature to simplify the debugging process.

An example of how to generate and run a reproducer using `compile_tool`, by making use of the `IE_NPU_CRASH_REPRODUCER_FILE` environment variable:

```sh
# Compile the model and generate a reproducer into the `reproducer.mlir`` file
IE_NPU_CRASH_REPRODUCER_FILE=reproducer.mlir compile_tool -d VPUX.3720 -ip FP16 -op FP16 -il NCHW -iml NCHW -ol NC -oml NC -m net.xml

# Execute the reproducer
vpux-opt --vpu-arch=VPUX37XX reproducer.mlir
```

It is also possible to generate reproducers with `vpux-opt` directly, by using the `--mlir-pass-pipeline-crash-reproducer` argument. For example:

```sh
# Generate the reproducer
vpux-opt --vpu-arch=VPUX37XX --convert-layers-to-VPU --mlir-pass-pipeline-crash-reproducer=reproducer.mlir net.mlir

# Execute the reproducer
vpux-opt --vpu-arch=VPUX37XX reproducer.mlir
```

### Local reproducers

MLIR can generate two kinds of reproducers: full or local scope. The full scope reproducers will include the original input IR, coupled with the full pipeline description which includes every individual pass with its own options. The local scope will only include the input IR to the crashing pass and the pass argument name, coupled with its options if any exist.

When compiling a network, the reproducer scope can be controlled using the `IE_NPU_GEN_LOCAL_REPRODUCER` environment variable:

* `IE_NPU_GEN_LOCAL_REPRODUCER=0` - full reproducer scope
* `IE_NPU_GEN_LOCAL_REPRODUCER=1` (default) - local reproducer scope


When using `vpux-opt`, the local reproducer can also be used. For example:

```sh
vpux-opt --vpu-arch=VPUX37XX --low-precision --mlir-pass-pipeline-crash-reproducer=reproducer.mlir --mlir-pass-pipeline-local-reproducer --mlir-disable-threading net.mlir
```

MLIR multi-threading has to be disabled when running the local reproducer. Internally, when using `IE_NPU_GEN_LOCAL_REPRODUCER` this is already handled, but using this option with `vpux-opt` requires it to be explicitly disabled.

To also note that when the local reproducer is used, MLIR will try to reduce the reproducer's scope to a local one. In case it cannot, it will fallback to a full scope.

More information can be found [here](https://mlir.llvm.org/docs/PassManagement/#crash-and-failure-reproduction).

## Printing MLIR objects

Many MLIR components come with their own printing interface. For example, `mlir::Operation`, `mlir::Type`, `mlir::Value` etc. have the `dump()` method which prints the data into the stderr stream. In order to print to another stream, the `print(raw_ostream &os)` method is available. Example usage:

```
mlir::Operation *op = ...;

op->dump();              // prints to stderr

op->print(llvm::outs()); // prints to stdout
```

It should also be possible to print to a file by using a `raw_fd_ostream` object.

**Note:** If printing something besides using dump, it may be worth ensuring the text is flushed using `std::endl` instead of `\n`. Otherwise, the extra text may be printed after the dumps are finished.

## Replace unsupported software operations

In case you are trying to see the compilation support for a network that has one or more unsupported software operations, there is a feature which can replace the operation with a dummy one. This way, the compilation can continue past the limitation of this missing operation, so that other potential issues can be identified.

The replacement of the unsupported software operations can be done by a compilation option. It should be placed in a configuration file, which is then passed to a tool such as `compile_tool` (e.g. using the `-c` argument). The configuration file should have the following content:

```
NPU_COMPILATION_MODE_PARAMS dummy-op-replacement=true
```

## Serializing canonical OV IR

In the frontend of the compiler, the OpenVINO model goes through a number of nGraph passes which perform some transformations over it. After these passes, the model gets parsed into the IE dialect from which the compiler starts running.

In order to dump the OpenVINO model that is obtained after the nGraph passes, use the following environment variable:

```sh
export NPU_SERIALIZE_CANONICAL_MODEL=1
```

## Selecting blob backend

The compiler supports two compilation backends: ELF and GraphFile. To switch between the two backends when compiling a network, for example when using `compile_tool`, the following configuration key is available which accepts values of `YES` or `NO`:

```
NPU_USE_ELF_COMPILER_BACKEND YES
```

This config can be placed in a text file that is passed to the compilatiion tool (e.g. using `-c` for `compile_tool`). On developer builds, the `IE_NPU_USE_ELF_COMPILER_BACKEND` environment variable can also be used.

As described in [this section](#compiling-a-model-using-vpux-translate--vpux-opt), it is also possible to use `vpux-translate` & `vpux-opt` in order to compile a model. The options given to the tools decide which backend is used:

```sh
# Import an OpenVINO IR into IE dialect
./vpux-translate --vpu-arch=VPUX37XX --import-IE <path to OV IR> -o net.mlir

# Use the GraphFile backend
./vpux-opt --vpu-arch=VPUX37XX --default-hw-mode net.mlir -o net_out.mlir
./vpux-translate --vpu-arch=VPUX37XX --export-VPUIP net_out.mlir > net.blob

# Use the ELF backend
./vpux-opt --vpu-arch=VPUX37XX --default-hw-mode --lower-VPUIP-to-ELF net.mlir -o net_out.mlir
./vpux-translate --vpu-arch=VPUX37XX --export-ELF net_out.mlir > net.blob
```

### Deserializing a GraphFile blob

GraphFile blobs use [flatbuffers](https://flatbuffers.dev/) for serialization. It is possible to deserialize these binaries into a JSON format, in order to investigate the content and debug it:

```sh
cd <openvino>/bin/<arch>/<build-type>
./flatc --json --defaults-json --strict-json --force-defaults lit-tests/schema/graphfile.fbs -- net.blob
```

A `net.json` file will be created which contains the deserialized blob. Changes can also be made to this JSON file, which can then be serialized back into a binary file:

```sh
./flatc -b lit-tests/schema/graphfile.fbs net.json
```

## Strategy manager JSON

The strategy manager supports the possibility of dumping a JSON file with the decisions taken with regards to the multi-clustering & tiling strategies for each operation. Similarly, the per-operation strategies can be manually set using a JSON file.

To dump the strategy decisions, one of the following options can be used:

```
// Using a configuration file passed to the compilation tool, such as compile_tool, with the following content:
NPU_COMPILATION_MODE_PARAMS write-strategy-to-json

// Using the following environment variable, available for Debug & developer builds
export IE_NPU_WRITE_STRATEGY_JSON=1
```

The strategies will be dumped into a file called `strategy_out.json`. The name of the file can be controlled in Debug and developer builds using the `IE_NPU_WRITE_STRATEGY_JSON_LOC` environment variable.

For manually forcing strategies for the layers, the following options are available:

```
// Using a configuration file passed to the compilation tool, such as compile_tool, with the following content:
NPU_COMPILATION_MODE_PARAMS read-strategy-from-json

// Using the following environment variable, available for Debug & developer builds
export IE_NPU_READ_STRATEGY_JSON=1
```

The strategies will be read from a file called `strategy_in.json`, but the name can also be controller for Debug and developer builds using the `IE_NPU_READ_STRATEGY_JSON_LOC` environment variable.

## Compiler schedule trace

At the end of compilation, there is a way to dump the final schedule to a JSON trace file and print additional performance metrics. For more details refer to [how-to-get-schedule-trace-and-analysis.md](../../../../guides/how-to-get-schedule-trace-and-analysis.md) guide.

## Memory scheduler statistics

The memory scheduler (`feasible-allocation` pass) can generate a scheduling JSON trace file and provide additional statistics about the schedule. This option is available for Debug and developer builds and can be controlled using the following environment variable:

```
export IE_NPU_ENABLE_SCHEDULE_STATISTICS=1
```

The resulting `scheduleTrace.json` file will contain an entry for each task of the following form:

```JSON
{"name":"TASK_NAME", "cat":"NCE", "ph":"X", "ts":0, "dur":7175, "pid":0, "tid":0},
```

## Profiling inference performance

The compiler supports generating blobs that can collect profiling information during the inference. The profiling feature can be enabled by using the following compilation option:

```
PERF_COUNT YES
```

There are three basic engines which can be independently enabled or disabled for profiling:
- **DMA profiling**: measures the duration of each DMA operation during the inference by wrapping it with DMAs from free running counter
    - it has an impact over the inference performance (up to 12% performance drop)
    - can be disabled with `NPU_COMPILATION_MODE_PARAMS dma-profiling=false`
- **DPU profiling**: measures the execution time of each DPU Task
    - it has an impact over the inference performance (up to 4% performance drop)
    - can be disabled with `NPU_COMPILATION_MODE_PARAMS dpu-profiling=false`
- **SW tasks profiling**: measures the execution time of each software task and collects the active and stall (DDR access failure) cycles for it.
    - affects performance similarly to DPU profiling
    - can be disabled with `NPU_COMPILATION_MODE_PARAMS sw-profiling=false`

For most platforms, all engines are enabled by default if the `PERF_COUNT` global profiling flag is set to enabled. Please check the value of the `dma-profiling`, `dpu-profiling` and `sw-profiling` pipeline options in order to see the default option for each platform.

By default, the printing of profiling information is done only using the standard OpenVINO API and benchmark_app tool, which reports summarized information for layer in the network. Using the special flag `"NPU_PRINT_PROFILING":"YES"` in the benchmark_app config, the printing of the full internal report of profiling data can be printed. When using InferenceManagerDemo with a blob that has profiling enabled, an additional `profiling-0.bin` file  will be generated which can be parsed to the same full report using the following command: `./prof_parser test.blob profiling-0.bin`

In order to enable profiling with `vpux-translate` & `vpux-opt`, use the `--vpux-profiling` option for `vpux-translate` and the `profiling=true` option for `vpux-opt`. For example:

```sh
./vpux-translate --vpu-arch=VPUX37XX --import-IE <path to OV IR> --vpux-profiling -o net.mlir
./vpux-opt --vpu-arch=VPUX37XX --default-hw-mode="profiling=true" net.mlir -o net_out.mlir
./vpux-translate --vpu-arch=VPUX37XX --export-VPUIP net_out.mlir > net.blob
```

More in-depth information can be found in the [how-to-use-profiling.md](../../../../guides/how-to-use-profiling.md) guide.

## VSCode

There are some Visual Studio Code extensions which can help improve the workflow with MLIR.

### MLIR extension

The [MLIR](https://marketplace.visualstudio.com/items?itemName=llvm-vs-code-extensions.vscode-mlir) extension can enable IDE features when working with MLIR-specific files, such as `.mlir` ones encountered in LIT tests or `.td` ones for TableGen definitions.

#### MLIRLSP

[MLIRLSP](https://mlir.llvm.org/docs/Tools/MLIRLSP/) allows more complex IDE integration (adds diagnostics, definition and references finding, hover information and easier navigation). By default, MLIR includes a tool called `mlir-lsp-server` which is useful when working only with the builtin dialects. For more complex cases, such as ours, a dedicated tool must be created that registers the dialects and passes. In our compiler, a tool called `npu-lsp-server` exists. This tool can be configured to be used in the MLIR extension.

**Note:** some `.mlir` files may not work properly when LSP is configured in the extension. This was observed when dumping some intermediate IR that contains constants with opaque content (e.g. the content is elided), since these constant operations cannot be parsed.

### Natvis LLVM & MLIR

This can customize how variables are displayed in the debugger, can simplify debugging for complex C++ types.

LLVM offers an `llvm.natvis` file which supports a number of classes coming with LLVM. For example, `SmallVector` for which it can display the size and capacity in the variable watch. The file can be found at the `thirdparty/llvm-project/llvm/utils/LLVMVisualizers/llvm.natvis` path.

In order to use the natvis file in VSCode, add the following to the cppdbg launch.json configuration:

```
"visualizerFile": "${workspaceFolder}/thirdparty/llvm-project/llvm/utils/LLVMVisualizers/llvm.natvis",
```

MLIR also has a natvis file at the `thirdparty/llvm-project/mlir/utils/MLIRVisualizers/mlir.natvis` path, however it is very small for the moment.

## General notes

### Assertions

It is recommended to use a Debug build for development, since assertions are active. On Release builds, the assertions are skipped, so the compilation might have undefined behavior. Debugging crashes due to assertions is also easy in Debug builds since debuggers such as gdb or lldb can stop at the crash point and offer a stack trace.

### Valgrind

[Valgrind](https://valgrind.org/) is a powerful collection of tools which can help identify cases of memory mismanagement, threading issues, but also profile the code. It can be called by prefixing the target command with `valgrind`. For example:

```
valgrind ./compile_tool ...
```
